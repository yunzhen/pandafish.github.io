<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Flink性能调优之序列化与反序列化</title>
    <link href="/2022/12/22/Flink%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <url>/2022/12/22/Flink%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<p>在Flink中序列化和反序列化是影响性能的一个重要因素。不合适的序列化器的使用以及过多的序列化反序列化操作都可能极大地影响性能。就我个人的经验来说，去除代码中多余的序列化操作使得吞吐量从2万提升到了8万。</p><p>本篇博文主要围绕以下内容展开：</p><ul><li>什么是序列化和反序列化？它通常用于什么地方？为什么序列化反序列化会较大地影响性能？</li><li>在Flink中哪些地方会用到序列化和反序列化？</li><li>针对序列化和反序列化的问题，该如何做性能优化？</li></ul><h1 id="序列化和反序列化的基本概念"><a href="#序列化和反序列化的基本概念" class="headerlink" title="序列化和反序列化的基本概念"></a>序列化和反序列化的基本概念</h1><h2 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h2><p>序列化： 将数据结构或对象转化为二进制串的过程<br>反序列化：将在序列化过程中所生成的二进制串转化为数据结构或者对象的过程。</p><p>对于java语言，二进制串指的是byte[]。因此在java中，把对象（如class 实例，String，Tuple等）转化为byte[]的过程就叫做序列化，反之就叫做反序列化。</p><p>为什么要进行序列化？一是为了数据持久化存储，二是为了数据网络传输。 都需要把不同语言特有的对象转化为通用的字节流。<br><img src="/2022/12/22/Flink%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/2022-12-23-17-08-24.png"></p><h2 id="序列化格式"><a href="#序列化格式" class="headerlink" title="序列化格式"></a>序列化格式</h2><p>我们以怎样的格式（协议）将对象转化为二进制串呢？序列化格式主要分为两类：文本格式和二进制格式。文本格式是把对象视为文本，按照字符编码的方式处理；而二进制格式则是将对象按照其在内存中的存储形式处理。两种格式只是对象转化为二进制串的方式不同，最终保存的都是二进制串。</p><p>举例来说</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">A</span>&#123;<br>    <span class="hljs-type">int</span> a;<br>    <span class="hljs-type">int</span> b;<br>&#125;<span class="hljs-built_in">s</span>(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>);<br></code></pre></td></tr></table></figure><p>json序列化(文本格式）的结果是：’{a:1,b:2} ‘是根据字符编码序列化为文本形式。而bson（二进制格式）则是内存中的数据按其在内存中的存储形式原样取出即可。</p><p>常见的序列化格式：xml,json,ProtoBuf,Thrift,MessagePack</p><p>文本格式的序列化可以将对象写出字符串，二进制格式的则不能。</p><h2 id="序列化工具"><a href="#序列化工具" class="headerlink" title="序列化工具"></a>序列化工具</h2><p>常见的Java序列化工具：</p><ul><li>Binary Formats &amp; language-specific ones<br>JavaBuiltIn（java原生）、JavaManual（根据成员变量类型，手工写）、FstSerliazation、Kryo</li><li>Binary formats-generic language-unspecific ones<br>Protobuf(Google)、Thrift(Facebook)、 AvroGeneric、Hessian</li><li>JSON Format<br>Jackson、Gson、FastJSON</li><li>JSON-like：<br>CKS （textual JSON-like format）、BSON（JSON-like format with extended datatypes）、JacksonBson、MongoDB</li><li>XML-based formats<br>XmlXStream</li></ul><h2 id="序列化和性能的关系"><a href="#序列化和性能的关系" class="headerlink" title="序列化和性能的关系"></a>序列化和性能的关系</h2><p>不同的序列化格式，不同的序列化工具对性能都有影响。这一块我没有深入研究。</p><p>但就我使用的Jackson而言，它的序列化和反序列化使用了java的反射机制，导致性能不高。</p><h1 id="Flink中序列化和反序列化"><a href="#Flink中序列化和反序列化" class="headerlink" title="Flink中序列化和反序列化"></a>Flink中序列化和反序列化</h1><p>上面提到了序列化和反序列化的用途就是数据传输和持久化存储。就一个Flink job而言，涉及到序列化和反序列化的也就是这两个场景。下面来细看。</p><h2 id="序列化和反序列化场景"><a href="#序列化和反序列化场景" class="headerlink" title="序列化和反序列化场景"></a>序列化和反序列化场景</h2><h3 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h3><ul><li>进程间： 有<br>如果不同的子任务处于不同的进程（taskmanager），数据需要经过网络传输，需要进行序列化和反序列化；  </li><li>同一个进程不同线程间： 有（通常的多线程是内存共享的，但flink不一定）<br>如果是同一个taskManager的不同线程的发送任务和接收任务，接收任务会将数据从字节缓冲区的数据拉取过来而不涉及网络通信开销，数据序列化后会先通过recordwriter，然后通过local channel发送给另一个task的input gate，然后反序列化，再交给recorder reader进行处理。 注意：线程间情况下，不管任务是不是在同一个slot上运行，数据传输都会进行序列化操作</li><li>同一个线程<br>通过传参的方式对象传输，不涉及序列化和通信；默认没有对象复3用，即深拷贝；开启对象复用后，为浅拷贝。</li></ul><h3 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h3><ul><li>rocketDB中状态读写，如果是Heap作为stateBackend，则状态的读写不涉及序列化和反序列化。</li><li>checkpoint和savepoint的存取；</li></ul><h2 id="Flink的序列化器"><a href="#Flink的序列化器" class="headerlink" title="Flink的序列化器"></a>Flink的序列化器</h2><p><img src="/2022/12/22/Flink%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/2022-10-28-10-47-09.png"><br><img src="/2022/12/22/Flink%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/2022-10-28-10-52-47.png"><br>注意： 采用第三方的序列化器需要采用对应的数据类型。</p><h2 id="各种序列化器性能的比较"><a href="#各种序列化器性能的比较" class="headerlink" title="各种序列化器性能的比较"></a>各种序列化器性能的比较</h2><p><img src="/2022/12/22/Flink%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E4%B9%8B%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/2022-10-27-17-37-41.png"></p><p>The fastest de&#x2F;serialization is achieved with Flink’s internal tuple and row serializers which can access these types’ fields directly without going via reflection. With roughly 30% decreased throughput as compared to tuples, Protobuf and POJO types do not perform too badly on their own and are more flexible and maintainable. Avro (specific and generic) records as well as Thrift data types further reduce performance by 20% and 30%, respectively. You definitely want to avoid Kryo as that reduces throughput further by around 50% and more!</p><p>序列化方案对吞吐量有很大的影响！！！</p><p>解决方案：<br>If you cannot use POJOs, try to define your data type with one of the serialization frameworks that generate specific code for it: Protobuf, Avro, Thrift (in that order, performance-wise).</p><h1 id="调优方法"><a href="#调优方法" class="headerlink" title="调优方法"></a>调优方法</h1><ol><li>减少不必要的序列化和反序列化。比如将可以合并的算子合并为算子链。</li><li>选择合适的数据类型以及序列化工具。这一块有机会再深入研究。</li></ol><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://bbs.huaweicloud.com/blogs/178415">谈谈Flink DataStream流计算中的优化</a></li><li><a href="https://flink.apache.org/news/2020/04/15/flink-serialization-tuning-vol-1.html">Flink Serialization Tuning Vol. 1: Choosing your Serializer — if you can</a></li><li><a href="https://blog.csdn.net/chufuying3/article/details/61640158">文本文件序列化和二进制序列化</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
      <tag>Performance Tuning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Flink维表关联方案</title>
    <link href="/2022/12/22/Flink%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94%E6%96%B9%E6%A1%88/"/>
    <url>/2022/12/22/Flink%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<p>数据流往往需要访问外部的数据源来丰富自己的信息，比如通过record中的ip地址查询ip数据库<a href="https://www.maxmind.com/en/geoip2-databases?gclid=CjwKCAiAnZCdBhBmEiwA8nDQxWDchxtuyFz3LazAPDl_LD6-aa2hxBwD02Ttq_a0XtmDB8Z_SG60vhoCCswQAvD_BwE">maxmind的GeoIP2 Databases</a>得到ip对应的城市名称，城市经纬度，将这些作为新的字段添加到原来的record中。这就涉及到本篇的主题：维表关联。</p><p>网上关于flink中维表关联的博文很多，本文我想谈一谈个人对不同方案的理解和尝试后发现的一些问题。如果想要比较全面地了解维表关联的各个解决方案，建议阅读参考文献前两篇。</p><h1 id="技术选型"><a href="#技术选型" class="headerlink" title="技术选型"></a>技术选型</h1><p>维表关联方案主要有以下几种</p><ul><li>实时数据库查找关联，又叫热存储维表</li><li>预加载维表关联</li><li>广播维表关联</li><li>维表变更日志关联，最常见的就是Temporal table function join</li></ul><p>这几种方案各有优劣，没有最好的方案，只有最适合的方案。</p><p>所谓<strong>实时数据库查找</strong>就是Flink中的算子保持与数据库的连接，每来一条record就提取关键字，直接查找外部的数据库。这个方案最致命的问题在于这种实时访问外部数据库进行查询的方式是很影响作业性能的，对数据库的负载很大，导致吞吐量很难提上去。而且大数据的流量一般都很大，频繁访问数据库导致产线上的数据库挂掉那就是重大的生产故障。当然，针对这个问题也有一些解决方案，比如同步查找可以替换为异步查找，还可以使用缓存使得热点数据直接在内存中就能找到不用访问外部数据库。Anyway,带来的性能提升效果有限，这种方案主要还是适用于流量不大的场景。</p><p><strong>预加载维表关联</strong>就是在任务启动的时候就把维表加载在内存中，查找的时候直接在内存中找就可以了。这个方案查找的性能是最高的，毕竟直接在内存中查找。但它也有一些局限性，一是占用更多的内存资源，如果维表非常大（比如大于TM内存），就不可取；二是维表很难实时更新，尽管可以设置定时器定时刷新维表，但是如果维表更新的太频繁性能消耗就太大了。总的来说，这种方案适合维表不是非常大，维表更新也不是很频繁的场景。（该方案实现简单，性能高，也是我最终选择的方案）</p><p>前面两种方案都属于数据流与静态的表之间的关联，而后面两种方案则是数据流与数据流之间的关联。所谓<strong>广播维表</strong>就是将维表转化为广播流从Source广播到下游的算子中，然后作为广播态保存到State Backend中，可以是内存，也可以是rocksdb。将广播态保存到rocksdb中每次读取状态都涉及到序列化和反序列化，对性能是有一定影响的。将广播态以MapState的形式保存在heap中和预加载维表关联就比较类似。</p><p>我这边将预加载维表关联和广播维表这两个方案做一个对比：</p><ol><li>都可以将完整的维表保存在内存中，维表查询性能较高。但是广播维表需要将维表从上游广播到下游，涉及到不同节点的数据传输（网络传输，序列化和反序列化等），会带来额外的性能损失。但是作为广播态保存，不同的slots可以共享广播态，每个TM只需要保存一份维表，而不是每个slots保存一份，内存的利用率更高。<br><img src="/2022/12/22/Flink%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94%E6%96%B9%E6%A1%88/2022-12-22-21-40-12.png"></li><li>广播维表需要把维表转化为数据流。好处是维表的实时性更高，方便实时更新。不好的地方是通常是把维表存储在Kafka中，考虑到实时性，实现上更复杂。也可以自定义source定时把最新的维表转化为数据流，和预加载维表的定时刷新方案一样，但这样维表更新就有延迟。</li><li>维表广播只能是数据流和一条广播流的join，不可以数据流和多条广播流join。预加载维表方案同一个算子可以预加载多个维表，维表广播的方案就需要把多个维表转化为同一个数据流进行广播，然后保存在不同名字的广播态中。实现起来比较复杂，另外就是代码聚合程度太高，很不优雅。</li></ol><p>总的来说，广播维表方案维表的实时性高，数据查询性能高，资源利用率也高，属于比较全面的一个方案。缺点主要在于实现上较为复杂，而且也要求维表不能太大。</p><p>最后提一下维表变更日志关联，主要是<strong>Temporal table function join</strong>。目前Datastream API不支持，需要写Table API&#x2F;Sql。这一块我没有做太多研究，就此不表。</p><h1 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h1><h2 id="实时查询外部数据库"><a href="#实时查询外部数据库" class="headerlink" title="实时查询外部数据库"></a>实时查询外部数据库</h2><h3 id="使用cache来减轻访问压力"><a href="#使用cache来减轻访问压力" class="headerlink" title="使用cache来减轻访问压力"></a>使用cache来减轻访问压力</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> join;<br><br><span class="hljs-keyword">import</span> com.google.common.cache.*;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.typeinfo.TypeHint;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;<br><span class="hljs-keyword">import</span> org.apache.flink.configuration.Configuration;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;<br><br><span class="hljs-keyword">import</span> java.util.HashMap;<br><span class="hljs-keyword">import</span> java.util.Map;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JoinDemo2</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br><br>        <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<br>        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; textStream = env.socketTextStream(<span class="hljs-string">&quot;localhost&quot;</span>, <span class="hljs-number">9000</span>, <span class="hljs-string">&quot;\n&quot;</span>)<br>                .map(p -&gt; &#123;<br>                    <span class="hljs-comment">//输入格式为：user,1000,分别是用户名称和城市编号</span><br>                    String[] list = p.split(<span class="hljs-string">&quot;,&quot;</span>);<br>                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple2</span>&lt;String, Integer&gt;(list[<span class="hljs-number">0</span>], Integer.valueOf(list[<span class="hljs-number">1</span>]));<br>                &#125;)<br>                .returns(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TypeHint</span>&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;<br>                &#125;);<br><br>        DataStream&lt;Tuple3&lt;String, Integer, String&gt;&gt; result = textStream.map(<span class="hljs-keyword">new</span> <span class="hljs-title class_">MapJoinDemo1</span>());<br>        result.print();<br>        env.execute(<span class="hljs-string">&quot;joinDemo1&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MapJoinDemo1</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">RichMapFunction</span>&lt;Tuple2&lt;String, Integer&gt;, Tuple3&lt;String, Integer, String&gt;&gt; &#123;<br>        LoadingCache&lt;Integer, String&gt; dim;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">open</span><span class="hljs-params">(Configuration parameters)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-comment">//使用google LoadingCache来进行缓存</span><br>            dim = CacheBuilder.newBuilder()<br>                    <span class="hljs-comment">//最多缓存个数，超过了就根据最近最少使用算法来移除缓存</span><br>                    .maximumSize(<span class="hljs-number">1000</span>)<br>                    <span class="hljs-comment">//在更新后的指定时间后就回收</span><br>                    .expireAfterWrite(<span class="hljs-number">10</span>, TimeUnit.MINUTES)<br>                    <span class="hljs-comment">//指定移除通知</span><br>                    .removalListener(<span class="hljs-keyword">new</span> <span class="hljs-title class_">RemovalListener</span>&lt;Integer, String&gt;() &#123;<br>                        <span class="hljs-meta">@Override</span><br>                        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">onRemoval</span><span class="hljs-params">(RemovalNotification&lt;Integer, String&gt; removalNotification)</span> &#123;<br>                            System.out.println(removalNotification.getKey() + <span class="hljs-string">&quot;被移除了，值为：&quot;</span> + removalNotification.getValue());<br>                        &#125;<br>                    &#125;)<br>                    .build(<br>                            <span class="hljs-comment">//指定加载缓存的逻辑</span><br>                            <span class="hljs-keyword">new</span> <span class="hljs-title class_">CacheLoader</span>&lt;Integer, String&gt;() &#123;<br>                                <span class="hljs-meta">@Override</span><br>                                <span class="hljs-keyword">public</span> String <span class="hljs-title function_">load</span><span class="hljs-params">(Integer cityId)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>                                    <span class="hljs-type">String</span> <span class="hljs-variable">cityName</span> <span class="hljs-operator">=</span> readFromHbase(cityId);<br>                                    <span class="hljs-keyword">return</span> cityName;<br>                                &#125;<br>                            &#125;<br>                    );<br><br>        &#125;<br><br>        <span class="hljs-keyword">private</span> String <span class="hljs-title function_">readFromHbase</span><span class="hljs-params">(Integer cityId)</span> &#123;<br>            <span class="hljs-comment">//读取hbase</span><br>            <span class="hljs-comment">//这里写死，模拟从hbase读取数据</span><br>            Map&lt;Integer, String&gt; temp = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>            temp.put(<span class="hljs-number">1001</span>, <span class="hljs-string">&quot;beijing&quot;</span>);<br>            temp.put(<span class="hljs-number">1002</span>, <span class="hljs-string">&quot;shanghai&quot;</span>);<br>            temp.put(<span class="hljs-number">1003</span>, <span class="hljs-string">&quot;wuhan&quot;</span>);<br>            temp.put(<span class="hljs-number">1004</span>, <span class="hljs-string">&quot;changsha&quot;</span>);<br>            <span class="hljs-type">String</span> <span class="hljs-variable">cityName</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br>            <span class="hljs-keyword">if</span> (temp.containsKey(cityId)) &#123;<br>                cityName = temp.get(cityId);<br>            &#125;<br><br>            <span class="hljs-keyword">return</span> cityName;<br>        &#125;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> Tuple3&lt;String, Integer, String&gt; <span class="hljs-title function_">map</span><span class="hljs-params">(Tuple2&lt;String, Integer&gt; value)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-comment">//在map方法中进行主流和维表的关联</span><br>            <span class="hljs-type">String</span> <span class="hljs-variable">cityName</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br>            <span class="hljs-keyword">if</span> (dim.get(value.f1) != <span class="hljs-literal">null</span>) &#123;<br>                cityName = dim.get(value.f1);<br>            &#125;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple3</span>&lt;&gt;(value.f0, value.f1, cityName);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="使用异步IO来提高访问吞吐量"><a href="#使用异步IO来提高访问吞吐量" class="headerlink" title="使用异步IO来提高访问吞吐量"></a>使用异步IO来提高访问吞吐量</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> join;<br><br><span class="hljs-keyword">import</span> org.apache.flink.api.common.typeinfo.TypeHint;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;<br><span class="hljs-keyword">import</span> org.apache.flink.configuration.Configuration;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.AsyncDataStream;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.functions.async.ResultFuture;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.functions.async.RichAsyncFunction;<br><span class="hljs-keyword">import</span> java.sql.DriverManager;<br><span class="hljs-keyword">import</span> java.sql.PreparedStatement;<br><span class="hljs-keyword">import</span> java.sql.ResultSet;<br><span class="hljs-keyword">import</span> java.util.ArrayList;<br><span class="hljs-keyword">import</span> java.util.List;<br><span class="hljs-keyword">import</span> java.util.concurrent.TimeUnit;<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JoinDemo3</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br><br>        <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<br>        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; textStream = env.socketTextStream(<span class="hljs-string">&quot;localhost&quot;</span>, <span class="hljs-number">9000</span>, <span class="hljs-string">&quot;\n&quot;</span>)<br>                .map(p -&gt; &#123;<br>                    <span class="hljs-comment">//输入格式为：user,1000,分别是用户名称和城市编号</span><br>                    String[] list = p.split(<span class="hljs-string">&quot;,&quot;</span>);<br>                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple2</span>&lt;String, Integer&gt;(list[<span class="hljs-number">0</span>], Integer.valueOf(list[<span class="hljs-number">1</span>]));<br>                &#125;)<br>                .returns(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TypeHint</span>&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;<br>                &#125;);<br><br><br>        DataStream&lt;Tuple3&lt;String,Integer, String&gt;&gt; orderedResult = AsyncDataStream<br>                <span class="hljs-comment">//保证顺序：异步返回的结果保证顺序，超时时间1秒，最大容量2，超出容量触发反压</span><br>                .orderedWait(textStream, <span class="hljs-keyword">new</span> <span class="hljs-title class_">JoinDemo3AyncFunction</span>(), <span class="hljs-number">1000L</span>, TimeUnit.MILLISECONDS, <span class="hljs-number">2</span>)<br>                .setParallelism(<span class="hljs-number">1</span>);<br><br>        DataStream&lt;Tuple3&lt;String,Integer, String&gt;&gt; unorderedResult = AsyncDataStream<br>                <span class="hljs-comment">//允许乱序：异步返回的结果允许乱序，超时时间1秒，最大容量2，超出容量触发反压</span><br>                .unorderedWait(textStream, <span class="hljs-keyword">new</span> <span class="hljs-title class_">JoinDemo3AyncFunction</span>(), <span class="hljs-number">1000L</span>, TimeUnit.MILLISECONDS, <span class="hljs-number">2</span>)<br>                .setParallelism(<span class="hljs-number">1</span>);<br><br>        orderedResult.print();<br>        unorderedResult.print();<br>        env.execute(<span class="hljs-string">&quot;joinDemo&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-comment">//定义个类，继承RichAsyncFunction，实现异步查询存储在mysql里的维表</span><br>    <span class="hljs-comment">//输入用户名、城市ID，返回 Tuple3&lt;用户名、城市ID，城市名称&gt;</span><br>    <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JoinDemo3AyncFunction</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">RichAsyncFunction</span>&lt;Tuple2&lt;String, Integer&gt;, Tuple3&lt;String, Integer, String&gt;&gt; &#123;<br>        <span class="hljs-comment">// 链接</span><br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">String</span> <span class="hljs-variable">jdbcUrl</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;jdbc:mysql://192.168.145.1:3306?useSSL=false&quot;</span>;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">String</span> <span class="hljs-variable">username</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;root&quot;</span>;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">String</span> <span class="hljs-variable">password</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;123&quot;</span>;<br>        <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">String</span> <span class="hljs-variable">driverName</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;com.mysql.jdbc.Driver&quot;</span>;<br>        java.sql.Connection conn;<br>        PreparedStatement ps;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">open</span><span class="hljs-params">(Configuration parameters)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-built_in">super</span>.open(parameters);<br><br>            Class.forName(driverName);<br>            conn = DriverManager.getConnection(jdbcUrl, username, password);<br>            ps = conn.prepareStatement(<span class="hljs-string">&quot;select city_name from tmp.city_info where id = ?&quot;</span>);<br>        &#125;<br><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">close</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-built_in">super</span>.close();<br>            conn.close();<br>        &#125;<br><br>        <span class="hljs-comment">//异步查询方法</span><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">asyncInvoke</span><span class="hljs-params">(Tuple2&lt;String, Integer&gt; input, ResultFuture&lt;Tuple3&lt;String,Integer, String&gt;&gt; resultFuture)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-comment">// 使用 city id 查询</span><br>            ps.setInt(<span class="hljs-number">1</span>, input.f1);<br>            <span class="hljs-type">ResultSet</span> <span class="hljs-variable">rs</span> <span class="hljs-operator">=</span> ps.executeQuery();<br>            <span class="hljs-type">String</span> <span class="hljs-variable">cityName</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br>            <span class="hljs-keyword">if</span> (rs.next()) &#123;<br>                cityName = rs.getString(<span class="hljs-number">1</span>);<br>            &#125;<br>            <span class="hljs-type">List</span> <span class="hljs-variable">list</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;Tuple2&lt;Integer, String&gt;&gt;();<br>            list.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple3</span>&lt;&gt;(input.f0,input.f1, cityName));<br>            resultFuture.complete(list);<br>        &#125;<br><br>        <span class="hljs-comment">//超时处理</span><br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">timeout</span><span class="hljs-params">(Tuple2&lt;String, Integer&gt; input, ResultFuture&lt;Tuple3&lt;String,Integer, String&gt;&gt; resultFuture)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>            <span class="hljs-type">List</span> <span class="hljs-variable">list</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;Tuple2&lt;Integer, String&gt;&gt;();<br>            list.add(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple3</span>&lt;&gt;(input.f0,input.f1, <span class="hljs-string">&quot;&quot;</span>));<br>            resultFuture.complete(list);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="预加载维表-定时刷新"><a href="#预加载维表-定时刷新" class="headerlink" title="预加载维表+定时刷新"></a>预加载维表+定时刷新</h2><p>我的维表是以文件的形式保存在本地磁盘中的。</p><p>如果是保存在外部数据库可参考参考文献4</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MyMapFunction</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">RichMapFunction</span>&lt;String,String&gt;&#123;<br>       <span class="hljs-keyword">private</span> <span class="hljs-keyword">transient</span> HashMap&lt;String, String&gt; hashMap;<br>       <span class="hljs-keyword">private</span> HashMap&lt;String,String&gt; <span class="hljs-title function_">readTxtFile</span><span class="hljs-params">(String filePath)</span> &#123;<br>           HashMap&lt;String,String&gt; hashMap = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>           <span class="hljs-type">File</span> <span class="hljs-variable">file</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(filePath);<br>           <span class="hljs-keyword">try</span> &#123;<br>               <span class="hljs-keyword">if</span> (file.isFile() &amp;&amp; file.exists()) &#123; <span class="hljs-comment">//判断文件是否存在</span><br>                   <span class="hljs-type">InputStreamReader</span> <span class="hljs-variable">read</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">InputStreamReader</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">FileInputStream</span>(file), <span class="hljs-string">&quot;UTF-8&quot;</span>);<span class="hljs-comment">//考虑到编码格式</span><br>                   <span class="hljs-type">BufferedReader</span> <span class="hljs-variable">bufferedReader</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">BufferedReader</span>(read);<br>                   <span class="hljs-comment">// String lineTxt = null;</span><br>                   <span class="hljs-keyword">while</span> (bufferedReader.readLine() != <span class="hljs-literal">null</span>) &#123;<br>                       <span class="hljs-type">String</span> <span class="hljs-variable">lineTxt</span> <span class="hljs-operator">=</span> bufferedReader.readLine();<br>                       String[] str = lineTxt.split(<span class="hljs-string">&quot;,&quot;</span>);<br>                       <span class="hljs-keyword">if</span> (str.length == <span class="hljs-number">2</span>) &#123;<br>                           hashMap.put(str[<span class="hljs-number">0</span>], str[<span class="hljs-number">1</span>]);<br>                       &#125;<br>                   &#125;<br>                   read.close();<br>               &#125; <span class="hljs-keyword">else</span> &#123;<br>                   System.out.println(<span class="hljs-string">&quot;找不到指定的文件&quot;</span>);<br>               &#125;<br>           &#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>               System.out.println(<span class="hljs-string">&quot;读取文件内容出错&quot;</span>);<br>               e.printStackTrace();<br>           &#125;<br>           <span class="hljs-keyword">return</span> hashMap;<br>       &#125;<br>       <span class="hljs-meta">@Override</span><br>       <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">open</span><span class="hljs-params">(Configuration parameters)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>           <span class="hljs-built_in">super</span>.open(parameters);<br><br>           <span class="hljs-type">String</span> <span class="hljs-variable">filePath</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;input/data100.txt&quot;</span>;<br><br>           <span class="hljs-type">ScheduledExecutorService</span> <span class="hljs-variable">timer</span> <span class="hljs-operator">=</span> Executors.newSingleThreadScheduledExecutor();<br>           timer.scheduleAtFixedRate(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Runnable</span>() &#123;<br>               <span class="hljs-meta">@Override</span><br>               <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">run</span><span class="hljs-params">()</span> &#123;<br>                   hashMap = readTxtFile(filePath);<br>               &#125;<br>           &#125;, <span class="hljs-number">0</span>, <span class="hljs-number">5</span>, TimeUnit.SECONDS);<br><br>       &#125;<br><br>       <span class="hljs-meta">@Override</span><br>       <span class="hljs-keyword">public</span> String <span class="hljs-title function_">map</span><span class="hljs-params">(String s)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>           <span class="hljs-keyword">return</span> hashMap.size() + <span class="hljs-string">&quot;&quot;</span>;<br>       &#125;<br>   &#125;<br> <br></code></pre></td></tr></table></figure><h2 id="广播态"><a href="#广播态" class="headerlink" title="广播态"></a>广播态</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> join;<br><br><span class="hljs-keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.state.BroadcastState;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.state.MapStateDescriptor;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.state.ReadOnlyBroadcastState;<br><span class="hljs-keyword">import</span> org.apache.flink.api.common.typeinfo.TypeHint;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.tuple.Tuple2;<br><span class="hljs-keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;<br><span class="hljs-keyword">import</span> org.apache.flink.configuration.Configuration;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.BroadcastStream;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;<br><span class="hljs-keyword">import</span> org.apache.flink.streaming.api.functions.co.BroadcastProcessFunction;<br><span class="hljs-keyword">import</span> org.apache.flink.util.Collector;<br><br><span class="hljs-keyword">import</span> java.util.ArrayList;<br><span class="hljs-keyword">import</span> java.util.HashMap;<br><span class="hljs-keyword">import</span> java.util.List;<br><span class="hljs-keyword">import</span> java.util.Map;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * 这个例子是从socket中读取的流，数据为用户名称和城市id，维表是城市id、城市名称，</span><br><span class="hljs-comment"> * 主流和维表关联，得到用户名称、城市id、城市名称</span><br><span class="hljs-comment"> * 这个例子采用 Flink 广播流的方式来做为维度</span><br><span class="hljs-comment"> **/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JoinDemo4</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>        <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<br>        <span class="hljs-comment">//定义主流</span><br>        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; textStream = env.socketTextStream(<span class="hljs-string">&quot;localhost&quot;</span>, <span class="hljs-number">9000</span>, <span class="hljs-string">&quot;\n&quot;</span>)<br>                .map(p -&gt; &#123;<br>                    <span class="hljs-comment">//输入格式为：user,1000,分别是用户名称和城市编号</span><br>                    String[] list = p.split(<span class="hljs-string">&quot;,&quot;</span>);<br>                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple2</span>&lt;String, Integer&gt;(list[<span class="hljs-number">0</span>], Integer.valueOf(list[<span class="hljs-number">1</span>]));<br>                &#125;)<br>                .returns(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TypeHint</span>&lt;Tuple2&lt;String, Integer&gt;&gt;() &#123;<br>                &#125;);<br><br>        <span class="hljs-comment">//定义城市流</span><br>        DataStream&lt;Tuple2&lt;Integer, String&gt;&gt; cityStream = env.socketTextStream(<span class="hljs-string">&quot;localhost&quot;</span>, <span class="hljs-number">9001</span>, <span class="hljs-string">&quot;\n&quot;</span>)<br>                .map(p -&gt; &#123;<br>                    <span class="hljs-comment">//输入格式为：城市ID,城市名称</span><br>                    String[] list = p.split(<span class="hljs-string">&quot;,&quot;</span>);<br>                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple2</span>&lt;Integer, String&gt;(Integer.valueOf(list[<span class="hljs-number">0</span>]), list[<span class="hljs-number">1</span>]);<br>                &#125;)<br>                .returns(<span class="hljs-keyword">new</span> <span class="hljs-title class_">TypeHint</span>&lt;Tuple2&lt;Integer, String&gt;&gt;() &#123;<br>                &#125;);<br><br>        <span class="hljs-comment">//将城市流定义为广播流</span><br>        <span class="hljs-keyword">final</span> MapStateDescriptor&lt;Integer, String&gt; broadcastDesc = <span class="hljs-keyword">new</span> <span class="hljs-title class_">MapStateDescriptor</span>(<span class="hljs-string">&quot;broad1&quot;</span>, Integer.class, String.class);<br>        BroadcastStream&lt;Tuple2&lt;Integer, String&gt;&gt; broadcastStream = cityStream.broadcast(broadcastDesc);<br><br>        <span class="hljs-type">DataStream</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> textStream.connect(broadcastStream)<br>                .process(<span class="hljs-keyword">new</span> <span class="hljs-title class_">BroadcastProcessFunction</span>&lt;Tuple2&lt;String, Integer&gt;, Tuple2&lt;Integer, String&gt;, Tuple3&lt;String, Integer, String&gt;&gt;() &#123;<br>                    <span class="hljs-comment">//处理非广播流，关联维度</span><br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processElement</span><span class="hljs-params">(Tuple2&lt;String, Integer&gt; value, ReadOnlyContext ctx, Collector&lt;Tuple3&lt;String, Integer, String&gt;&gt; out)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>                        ReadOnlyBroadcastState&lt;Integer, String&gt; state = ctx.getBroadcastState(broadcastDesc);<br>                        <span class="hljs-type">String</span> <span class="hljs-variable">cityName</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;&quot;</span>;<br>                        <span class="hljs-keyword">if</span> (state.contains(value.f1)) &#123;<br>                            cityName = state.get(value.f1);<br>                        &#125;<br>                        out.collect(<span class="hljs-keyword">new</span> <span class="hljs-title class_">Tuple3</span>&lt;&gt;(value.f0, value.f1, cityName));<br>                    &#125;<br><br>                    <span class="hljs-meta">@Override</span><br>                    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processBroadcastElement</span><span class="hljs-params">(Tuple2&lt;Integer, String&gt; value, Context ctx, Collector&lt;Tuple3&lt;String, Integer, String&gt;&gt; out)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>                        System.out.println(<span class="hljs-string">&quot;收到广播数据：&quot;</span> + value);<br>                        ctx.getBroadcastState(broadcastDesc).put(value.f0, value.f1);<br>                    &#125;<br>                &#125;);<br><br><br>        result.print();<br>        env.execute(<span class="hljs-string">&quot;joinDemo&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ol><li><a href="https://blog.csdn.net/qq_36039236/article/details/111885049">实时数仓之Flink维表关联难点解决方案</a></li><li><a href="https://www.cnblogs.com/importbigdata/articles/15665325.html">Flink重点难点：维表关联理论和Join实战</a></li><li><a href="https://zhuanlan.zhihu.com/p/272651870">Flink State 误用之痛，你中招了吗?</a></li><li><a href="https://www.jianshu.com/p/fe711f0b3e81">Flink 维表关联之全量预加载+定时刷新</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
      <tag>Dimension Table join</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从0开始部署一个Flink集群：理论篇</title>
    <link href="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/"/>
    <url>/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>本系列博文由3篇文章组成：</p><ul><li><a href="https://yunzhen.github.io/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/">从0开始部署一个Flink集群：理论篇</a></li><li><a href="https://yunzhen.github.io/2022/12/18/Flink%E9%83%A8%E7%BD%B2%E7%8B%AC%E7%AB%8B%E9%83%A8%E7%BD%B2%E7%AF%87/">从0开始部署一个Flink集群：实践篇（独立部署）</a></li><li><a href="https://yunzhen.github.io/2022/12/19/Flink%E9%83%A8%E7%BD%B2k8s%E7%AF%87/">从0开始部署一个Flink集群：实践篇（Native k8s部署）</a></li></ul><p>主要回答以下问题：</p><ul><li>Flink集群是由哪些组件组成的？它们彼此之间如何协调工作的？</li><li>在Flink中job, task, slots,parallelism是什么意思？集群中的资源是如何调度和分配的？</li><li>如何搭建一个Flink集群？如何配置高可用服务？如何使用外部文件系统？</li></ul><h1 id="Flink系统架构"><a href="#Flink系统架构" class="headerlink" title="Flink系统架构"></a>Flink系统架构</h1><p><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-21-20-36-32.png"></p><p>Flink的核心组件包含客户端，jobmanager（JM）和taskmanager(TM)三部分。此外Flink往往还需要结合很多外部组件一起使用，比如高可用服务、持久化存储、资源管理、指标存储与分析的组件。</p><p>Flink客户端主要负责将job提交给JM。JM是中央调度器，包含Jobmaster, Dispatcher, ResourceManager三部分。<strong>JobMaster</strong> is responsible for managing the execution of a single JobGraph. Multiple jobs can run simultaneously in a Flink cluster, each having its own JobMaster. <strong>The Dispatcher</strong> provides a REST interface to submit Flink applications for execution and starts a new JobMaster for each submitted job. It also runs the Flink WebUI to provide information about job executions. <strong>The ResourceManager</strong> is responsible for resource de-&#x2F;allocation and provisioning in a Flink cluster — it manages task slots, which are the unit of resource scheduling in a Flink cluster. TM负责执行具体的任务。</p><p>如果只是提交作业和执行作业，不考虑整个集群的稳定性，拓展性，便于维护的性能等，只部署以上三个组件就够了。</p><p>但是，如果TM done掉了，JM还可以控制任务重启在其它TM上；如果JM done掉了，所有的任务都将失败，因此我们需要部署<strong>高可用服务</strong>使得一个JM done掉后，备用的JM 自动地顶上去作业。Flink目前（1.16）仅支持两种高可用服务：Zookeeper HA service 和 K8s HA service.</p><p>Flink有<strong>故障恢复</strong>的机制在任务失败后重启任务，并读取任务失败前的状态在这个状态下继续工作，可以保证哪怕任务失败重启，数据也不丢失，不重发。而这个“任务失败前的状态”是通过checkpoint保存的，考虑到多个JM需要共享checkpoint，checkpoint往往保存在可共享的持久化外部存储系统中，比如HDFS，S3等。因此我们还需要部署文件存储系统。</p><p>再说集群的资源管理和调度，Flink支持k8s和YARN两种工具来自动化管理集群资源，也可以不依赖于任何<strong>Resource Provider</strong>，采用独立部署（standalone）方式部署集群。</p><p>再说集群的监控，Flink本身收集了很多指标，可以通过<strong>metrics reporter</strong>与外部的指标存储、分析、展示工具一起搭建一个Flink监控系统。比如联合Prometheus, grafana搭建监控系统。</p><h1 id="Flink的作业执行机制"><a href="#Flink的作业执行机制" class="headerlink" title="Flink的作业执行机制"></a>Flink的作业执行机制</h1><p>在讲解Flink不同的部署方式以及不同部署方式下各组件如何协调工作前，我认为很有必要讲解一下Flink的作业执行机制，便于理解之后会反复提到的JobGraph，task, slots等概念。</p><h2 id="DataFlows和Operator"><a href="#DataFlows和Operator" class="headerlink" title="DataFlows和Operator"></a>DataFlows和Operator</h2><p>程序运行时会被映射为dataflows,每个数据流都是以一个或多个sources开始，一个或多个sinks结束，类似于任意的有向无环图。大多数情况下，程序中的转换运算和dataflow中的算子（operator)是一一对应的关系。</p><p>比如下图中的程序就可以转化为由source，map算子，分组聚合算子，sink组成的数据流。<br><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-21-21-47-01.png"></p><h2 id="并行计算和并行度（Parallelism"><a href="#并行计算和并行度（Parallelism" class="headerlink" title="并行计算和并行度（Parallelism)"></a>并行计算和并行度（Parallelism)</h2><p><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-21-21-49-48.png"></p><p>任务并行：不同的任务（算子）并行处理不同的数据，数据流图中横向的同时执行。</p><p>数据并行：一个算子可以包含一个或多个子任务，这些子任务在不同的线程、不同的物理机或容器中完全独立地执行。</p><p>并行度：一个特定<strong>算子</strong>的子任务个数，指的数据并行。有些像多线程的线程数，但和多线程不一样的是，多线程的子线程共享内存资源，但是一个算子的子任务运行在不同的slot上，内存资源是隔离的。注意并行度针对的是算子，不同的算子可以设置为不同的并行度。</p><p>并行度的设置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//全局，不推荐</span><br>env.setParallelism(<span class="hljs-number">1</span>);<br><span class="hljs-comment">//每一个算子</span><br>source.map(...).setParallelism(<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><p>并行度的执行规则：底层实现&gt;代码局部&gt;代码全局设置&gt;提交任务时的命令行设置&gt;配置文件的默认设置</p><h2 id="算子链"><a href="#算子链" class="headerlink" title="算子链"></a>算子链</h2><p>上面介绍了数据流图，算子，并行度的概念，再来说什么是算子链。</p><p>Flink中算子与算子之间的数据传输形式大体可以分为以下两类：</p><ul><li><p>one-to-one(forwarding) 直通：</p><p>  从一个算子到另一个算子的分区不变，比如source和map之间，这代表着map算子的子任务看到的元素的个数和顺序和source算子的子任务产生的相同。map,filter,flatMap都属于这种（前提是并行度不变）</p></li><li><p>redistributing(重分配）：</p><p>  stream的分区会发生改变，如keyby.</p></li></ul><p>如果前后两个算子并行度相同，且传输方式为one-to-one就可以合并为一个算子链。通常我们说的<strong>task</strong>就是指的一个算子链，<strong>subtask</strong>往往指的同一算子链的子任务。</p><p>算子合并为算子链是作业执行中很重要的一个优化手段，是否合并是可以通过代码控制的，在作业的性能调优中也是一个可以考虑的调优点。</p><p>Flink中之所以合并算子主要考虑的是减少算子之间不必要的数据传输，因为在flink中，不同任务之间的数据传输带来的性能开销其实并不小，一是数据传输必然涉及到序列化和反序列，要是一条数据很大，又选择了不合适的数据类型比如json，那带来的性能损耗是非常明显的；二是如果任务处于不同的taskmanager，那数据传输还涉及到网络传输。另外合并算子也减少了整个job的线程数，能够减少线程转化的开销。</p><p>需要注意的是，合并算子并不一定能带来性能提升的，因为算子合并其实相当于减少了并发，可能会影响CPU利用率，可以参考多线程的线程数考虑这一点。</p><h2 id="执行图（ExecutionGraph"><a href="#执行图（ExecutionGraph" class="headerlink" title="执行图（ExecutionGraph)"></a>执行图（ExecutionGraph)</h2><p>相关概念介绍完后，简单介绍一下（很多细节还未搞明白，但尚不影响使用）一个Flink作业是如何一步步转化为Taskmanager上可以执行的task的。下面的描述主要针对Session部署方式，对于Application部署模式之后再介绍。</p><p>首先，客户端会将代码转化为dataflow，dataflow进一步优化如合并算子链后生成JobGraph。<br><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-21-22-37-05.png"></p><p>然后，JM对JobGraph根据并行度进行拆分生成执行图，<br><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-21-22-38-45.png"></p><p>最后JM会分发执行图到taskmanager上，实际执行的叫物理执行图。</p><h1 id="Flink的资源分配和调度"><a href="#Flink的资源分配和调度" class="headerlink" title="Flink的资源分配和调度"></a>Flink的资源分配和调度</h1><p>slots是Flink中资源分配的最小单位。Flink对内存资源是进行了隔离的，隔离出来的每一份资源叫一个slot。每个TM通过参数taskmanager.numberOfTaskSlots配置slots的数量。建议根据核的数量分配任务槽，这样一个任务槽就一个cpu核，cpu就不需要分时复用了。默认slots平分整个TM的内存资源，Flink也支持细粒度地划分slots的资源。<br><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-22-09-52-13.png"></p><p>需要配置cluster.fine-grained-resource-management.enabled为true</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">final</span> <span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<br><br><span class="hljs-type">SlotSharingGroup</span> <span class="hljs-variable">ssgA</span> <span class="hljs-operator">=</span> SlotSharingGroup.newBuilder(<span class="hljs-string">&quot;a&quot;</span>)<br>  .setCpuCores(<span class="hljs-number">1.0</span>)<br>  .setTaskHeapMemoryMB(<span class="hljs-number">100</span>)<br>  .build();<br><br><span class="hljs-type">SlotSharingGroup</span> <span class="hljs-variable">ssgB</span> <span class="hljs-operator">=</span> SlotSharingGroup.newBuilder(<span class="hljs-string">&quot;b&quot;</span>)<br>  .setCpuCores(<span class="hljs-number">0.5</span>)<br>  .setTaskHeapMemoryMB(<span class="hljs-number">100</span>)<br>  .build();<br><br>someStream.filter(...).slotSharingGroup(<span class="hljs-string">&quot;a&quot;</span>) <span class="hljs-comment">// Set the slot sharing group with name “a”</span><br>.map(...).slotSharingGroup(ssgB); <span class="hljs-comment">// Directly set the slot sharing group with name and resource.</span><br><br>env.registerSlotSharingGroup(ssgA); <span class="hljs-comment">// Then register the resource of group “a”</span><br></code></pre></td></tr></table></figure><p><img src="/2022/12/21/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E9%83%A8%E7%BD%B2%E4%B8%80%E4%B8%AAFlink%E9%9B%86%E7%BE%A4/2022-12-21-22-54-12.png"></p><p>上面讲的是资源的分配，再讲资源的调度：不同的task如何分配到slots上面。 主要遵守下面两个原则： 同一个任务的不同子任务只能分配到不同的slots上；多个任务可以共享slot。以上图为例，一共3个算子链，并行度分别为6，6，1，每个算子链在slots上依次分配，同一个Job的不同算子链共享slot的。</p><p>基于这样的资源调度规则，就不难理解“一个job需要的任务槽的数量至少为算子链的最大并行度“。像上面的示例，需要的任务槽数量就是6。</p><p>为什么slots可以共享？不同的task资源完全隔离不好吗？这里主要是从提高资源的利用率考虑的，希望各个内存区域的使用相对均衡，而不是忙的忙死闲的闲死。</p><h1 id="Flink的部署"><a href="#Flink的部署" class="headerlink" title="Flink的部署"></a>Flink的部署</h1><p>Flink提供了3种部署模式：</p><ul><li>会话模式（Session Mode)</li><li>单作业模式（Per-Job Mode)</li><li>应用模式（Application Mode)</li></ul><p>它们的区别主要在于：集群的生命周期以及资源的分配方式；应用的Main方法在哪里执行——客户端还是JobManager。 其中Per-Job模式在1.15版本后已经废弃，就不再介绍了。</p><h2 id="会话模式"><a href="#会话模式" class="headerlink" title="会话模式"></a>会话模式</h2><p>先启动集群，保持一个会话，在这个会话中通过客户端提交作业。集群启动时所有资源就都已经确定，所以所有提交的作业会竞争集群中的资源。一个任务导致集群崩溃会牵连其他所有任务。</p><p>会话模式适合单个规模小、执行时间短的大量作业。（因为执行时间短，所以单个作业占用的资源很快能释放掉给下一个作业使用，不需要反复启动集群，反复部署资源）</p><h2 id="应用模式"><a href="#应用模式" class="headerlink" title="应用模式"></a>应用模式</h2><p>应用模式是提交任务的同时启动集群，一个应用一个集群，应用在集群在，应用亡集群自动关闭。此外，应用模式的另一个显著特点是应用的main方法执行在JM，而不是客户端。这样做是为了减轻客户端的负载，避免当多个用户同时提交任务时客户端宕机。</p><p>那么，main方法的执行为什么会带来较大的负载呢？执行main方法首先需要下载相关的依赖，还需要抽取拓扑结构（比如JobGraph）便于后续的处理。客户端执行完后还需要把这些都传输给JM。这就使得客户端一是需要格外的网络带宽下载依赖，传输数据给JM; 二是消耗更多的CPU。因此application模式把这部分的工作放在了JM上。</p><p>官方推荐在产线上使用应用模式，在测试开发中使用会话模式。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://flink.apache.org/">official document</a></li><li><a href="https://www.bilibili.com/video/BV133411s7Sa/?vd_source=4ae95225239e82c38fe3a820e863882e">B站视频</a></li><li><a href="https://confucianzuoyuan.github.io/flink-tutorial/book/chapter02-01-02-%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%92%8C%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C.html">尚硅谷课程教材</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
      <tag>Cluster Deployment</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从0开始部署一个Flink集群：实践篇（Native k8s部署）</title>
    <link href="/2022/12/19/Flink%E9%83%A8%E7%BD%B2k8s%E7%AF%87/"/>
    <url>/2022/12/19/Flink%E9%83%A8%E7%BD%B2k8s%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<p>上一篇博文介绍了如何独立部署一个高可用的Flink集群,本篇介绍如何用Native k8s去部署高可用的Flink 集群。本篇介绍的集群构建在AWS上，和构建在自己的服务器相比，主要区别在文件系统的选择和使用上。我选用的S3服务。</p><ul><li>EC2操作系统：centos7</li><li>本机操作系统：Mac</li><li>flink version: 1.14</li><li>jdk version: java8</li><li>HA service: k8s</li><li>File System: S3</li></ul><h1 id="启动EC2"><a href="#启动EC2" class="headerlink" title="启动EC2"></a>启动EC2</h1><p>在AWS上启动3个EC2,操作系统选centos7,注意每个EC2要关联弹性ip地址，允许外网访问。<br>可参考<a href="https://wiki.centos.org/Cloud/AWS">https://wiki.centos.org/Cloud/AWS</a></p><h1 id="部署k8s集群"><a href="#部署k8s集群" class="headerlink" title="部署k8s集群"></a>部署k8s集群</h1><h2 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo yum-config-manager --add-repo https:<span class="hljs-regexp">//</span>download.docker.com<span class="hljs-regexp">/linux/</span>centos/docker-ce.repo<br>sudo yum install docker -y<br>sudo systemctl start docker.service<br>sudo systemctl enable docker.service<br>sudo systemctl status docker<br></code></pre></td></tr></table></figure><h2 id="安装k8s"><a href="#安装k8s" class="headerlink" title="安装k8s"></a>安装k8s</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ sudo vi <span class="hljs-regexp">/etc/yum</span>.repos.d/kubernetes.repo<br>[kubernetes]<br>name=Kubernetes<br>baseurl=https:<span class="hljs-regexp">//</span>packages.cloud.google.com<span class="hljs-regexp">/yum/</span>repos/kubernetes-el7-x86_64<br>enabled=<span class="hljs-number">1</span><br>gpgcheck=<span class="hljs-number">1</span><br>repo_gpgcheck=<span class="hljs-number">0</span><br>gpgkey=https:<span class="hljs-regexp">//</span>packages.cloud.google.com<span class="hljs-regexp">/yum/</span>doc<span class="hljs-regexp">/yum-key.gpg https:/</span><span class="hljs-regexp">/packages.cloud.google.com/yum</span><span class="hljs-regexp">/doc/</span>rpm-package-key.gpg<br>$ sudo yum install -y kubelet<br>$ sudo yum install -y kubeadm<br>$ sudo systemctl enable kubelet<br></code></pre></td></tr></table></figure><h2 id="Linux环境准备"><a href="#Linux环境准备" class="headerlink" title="Linux环境准备"></a>Linux环境准备</h2><ol><li>set hostnames</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// On your **Master** node, update your hostname using the following command:</span><br><br><span class="hljs-comment">//Master:192.168.100.90 (3.101.77.138)</span><br><br>$ sudo hostnamectl set-hostname master-node<br><br><span class="hljs-comment">//worker-node1:192.168.100.29 (3.101.77.139)</span><br><br>$ sudo hostnamectl set-hostname worker-node1<br><br><span class="hljs-comment">// worker-node2: 192.168.100.21 (3.101.77.140)</span><br><br>$ sudo hostnamectl set-hostname worker-node2<br><br><span class="hljs-comment">// Make a host entry or DNS record to resolve the hostname for all nodes:</span><br><br>$ sudo vi /etc/hosts<br><br><span class="hljs-comment">// With the entry:</span><br><br><span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-number">.63</span>  master-node<br><br><span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-number">.36</span> node1 worker-node1<br><br><span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-number">.125</span> node2 worker-node2<br></code></pre></td></tr></table></figure><ol start="2"><li>关闭SElinux<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java">$ sudo setenforce <span class="hljs-number">0</span><br>$ sudo sed -i --follow-symlinks <span class="hljs-string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;</span> /etc/sysconfig/selinux<br>$ sudo reboot<br>$ sestatus<br>SELinux status:                 disabled<br></code></pre></td></tr></table></figure></li><li>update iptables config</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">$ sudo vi /etc/sysctl.d/k8s.conf<br>net.bridge.bridge-nf-call-ip6tables = <span class="hljs-number">1</span><br>net.bridge.bridge-nf-call-iptables = <span class="hljs-number">1</span><br>$ sudo sysctl --system<br></code></pre></td></tr></table></figure><ol start="4"><li>disable swap(3)</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">$ sudo sed -i <span class="hljs-string">&#x27;/swap/d&#x27;</span> /etc/fstab<br>$ sudo swapoff -a<br></code></pre></td></tr></table></figure><h2 id="部署k8s集群-1"><a href="#部署k8s集群-1" class="headerlink" title="部署k8s集群"></a>部署k8s集群</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// only master node</span><br>$ sudo kubeadm init<br>kubeadm join <span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-number">.63</span>:<span class="hljs-number">6443</span> --token snmpyy.b4y506h6hr9u7fxh \<br>        --discovery-token-ca-cert-hash sha256:87a099765ce369c519bc02af84a6d4732b1cb987d3e95277b334e3cfc3aa0960<br><span class="hljs-comment">// Create required directories and start managing Kubernetes cluster</span><br>$ mkdir -p $HOME/.kube<br>$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config<br>$ sudo chown $(id -u):$(id -g) $HOME/.kube/config<br>[ec2-user<span class="hljs-meta">@master</span>-node kubernetes]$ kubectl get nodes<br>NAME          STATUS     ROLES           AGE   VERSION<br>master-node   NotReady   control-plane   84m   v1<span class="hljs-number">.24</span><span class="hljs-number">.2</span><br><span class="hljs-comment">//Set up Pod network for the Cluster</span><br>$ export kubever=$(kubectl version | base64 | tr -d <span class="hljs-string">&#x27;\n&#x27;</span>)<br>$ kubectl apply -f https:<span class="hljs-comment">//cloud.weave.works/k8s/net?k8s-version=$kubever</span><br><span class="hljs-comment">// add nodes to your cluster</span><br><span class="hljs-comment">//在两个工作节点操作</span><br>$ kubeadm join <span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-number">.63</span>:<span class="hljs-number">6443</span> --token snmpyy.b4y506h6hr9u7fxh \<br>        --discovery-token-ca-cert-hash sha256:87a099765ce369c519bc02af84a6d4732b1cb987d3e95277b334e3cfc3aa0960<br><span class="hljs-comment">//在master节点</span><br>$ kubectl label node worker-node1 node-role.kubernetes.io/worker=worker<br>$ kubectl label node worker-node2 node-role.kubernetes.io/worker=worker<br><br></code></pre></td></tr></table></figure><h1 id="Session-Mode-部署Flink集群"><a href="#Session-Mode-部署Flink集群" class="headerlink" title="Session Mode 部署Flink集群"></a>Session Mode 部署Flink集群</h1><h2 id="安装Java8"><a href="#安装Java8" class="headerlink" title="安装Java8"></a>安装Java8</h2><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">$ sudo yum search <span class="hljs-keyword">java|grep </span><span class="hljs-keyword">jdk</span><br><span class="hljs-keyword"></span>$ sudo yum <span class="hljs-keyword">install </span>-y <span class="hljs-keyword">java-1.8.0-openjdk</span><br><span class="hljs-keyword"></span>$ sudo yum <span class="hljs-keyword">install </span><span class="hljs-keyword">java-1.8.0-openjdk-devel </span>-y<br>$ <span class="hljs-keyword">java </span>-version<br></code></pre></td></tr></table></figure><h2 id="下载解压Flink安装包"><a href="#下载解压Flink安装包" class="headerlink" title="下载解压Flink安装包"></a>下载解压Flink安装包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cd</span> /opt</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">wget https://dlcdn.apache.org/flink/flink-1.15.2/flink-1.15.2-bin-scala_2.12.tgz --no-check-certificate</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">tar -xzf flink-*.tgz</span><br></code></pre></td></tr></table></figure><h2 id="启动集群（无高可用服务版本）"><a href="#启动集群（无高可用服务版本）" class="headerlink" title="启动集群（无高可用服务版本）"></a>启动集群（无高可用服务版本）</h2><p>Native k8s是把k8s植入到了Flink安装包中，直接使用Flink的命令就可以在k8s集群中启动flink组件相关的pod。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">//service account <span class="hljs-keyword">with</span> RBAC permissions <span class="hljs-keyword">to</span> <span class="hljs-keyword">create</span>, <span class="hljs-keyword">delete</span> pods<br>$ kubectl <span class="hljs-keyword">create</span> namespace flink-<span class="hljs-keyword">cluster</span><br>$ kubectl <span class="hljs-keyword">create</span> serviceaccount flink -n flink-<span class="hljs-keyword">cluster</span><br>$ kubectl <span class="hljs-keyword">create</span> clusterrolebinding flink-<span class="hljs-keyword">role</span>-binding-flink \<br>  <span class="hljs-comment">--clusterrole=edit \</span><br>  <span class="hljs-comment">--serviceaccount=flink-cluster:flink</span><br>//启动<span class="hljs-keyword">session</span>集群<span class="hljs-number">1</span>（此时读取的配置为master节点的配置文件，与taskmanager节点的配置文件无关）<br>$ ./bin/kubernetes-<span class="hljs-keyword">session</span>.sh -Dkubernetes.namespace=flink-<span class="hljs-keyword">cluster</span> -Dkubernetes.jobmanager.service-account=flink -Dkubernetes.<span class="hljs-keyword">cluster</span>-id=my-<span class="hljs-keyword">session</span> -Dtaskmanager.numberOfTaskSlots=<span class="hljs-number">6</span>  -Dkubernetes.rest-service.exposed.<span class="hljs-keyword">type</span>=NodePort<br><span class="hljs-number">2022</span><span class="hljs-number">-07</span><span class="hljs-number">-01</span> <span class="hljs-number">08</span>:<span class="hljs-number">46</span>:<span class="hljs-number">49</span>,<span class="hljs-number">621</span> <span class="hljs-keyword">INFO</span>  org.apache.flink.kubernetes.KubernetesClusterDescriptor      [] - <span class="hljs-keyword">Create</span> flink <span class="hljs-keyword">session</span> <span class="hljs-keyword">cluster</span> my-<span class="hljs-keyword">session</span> successfully, JobManager Web Interface: http://<span class="hljs-number">192.168</span><span class="hljs-number">.100</span><span class="hljs-number">.63</span>:<span class="hljs-number">32172</span><br>// Dashboard: http://<span class="hljs-number">3.101</span><span class="hljs-number">.77</span><span class="hljs-number">.141</span>:<span class="hljs-number">32172</span>/,此时没有任何资源\<br><br>//只部署了jobmanager，部署在worker-node1,两个服务，一个对内，一个对外<br>[root@master-node ec2-<span class="hljs-keyword">user</span>]# kubectl <span class="hljs-keyword">get</span> pods,svc,ep -n flink-<span class="hljs-keyword">cluster</span> -o wide<br><span class="hljs-type">NAME</span>                      <span class="hljs-keyword">TYPE</span>        <span class="hljs-keyword">CLUSTER</span>-IP      <span class="hljs-keyword">EXTERNAL</span>-IP   PORT(S)             AGE    SELECTOR<br>service/my-<span class="hljs-keyword">session</span>        ClusterIP   <span class="hljs-keyword">None</span>            &lt;<span class="hljs-keyword">none</span>&gt;        <span class="hljs-number">6123</span>/TCP,<span class="hljs-number">6124</span>/TCP   <span class="hljs-number">124</span>m   app=my-<span class="hljs-keyword">session</span>,component=jobmanager,<span class="hljs-keyword">type</span>=flink-native-kubernetes<br>service/my-<span class="hljs-keyword">session</span>-rest   NodePort    <span class="hljs-number">10.109</span><span class="hljs-number">.225</span><span class="hljs-number">.42</span>   &lt;<span class="hljs-keyword">none</span>&gt;        <span class="hljs-number">8081</span>:<span class="hljs-number">31595</span>/TCP      <span class="hljs-number">124</span>m   app=my-<span class="hljs-keyword">session</span>,component=jobmanager,<span class="hljs-keyword">type</span>=flink-native-kubernetes<br><br><span class="hljs-type">NAME</span>                              READY   STATUS    RESTARTS   AGE    IP          NODE           NOMINATED NODE   READINESS GATES<br>pod/my-<span class="hljs-keyword">session</span><span class="hljs-number">-556</span>f44f44b<span class="hljs-number">-94</span>gfk   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">124</span>m   <span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>   worker-node1   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br><br><span class="hljs-type">NAME</span>                        ENDPOINTS                       AGE<br>endpoints/my-<span class="hljs-keyword">session</span>        <span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>:<span class="hljs-number">6124</span>,<span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>:<span class="hljs-number">6123</span>   <span class="hljs-number">124</span>m<br>endpoints/my-<span class="hljs-keyword">session</span>-rest   <span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>:<span class="hljs-number">8081</span>                  <span class="hljs-number">124</span>m<br>[root@master-node ec2-<span class="hljs-keyword">user</span>]# kubectl <span class="hljs-keyword">get</span> deployment -o wide -n flink-<span class="hljs-keyword">cluster</span><br><span class="hljs-type">NAME</span>         READY   UP-<span class="hljs-keyword">TO</span>-<span class="hljs-type">DATE</span>   AVAILABLE   AGE    CONTAINERS             IMAGES                           SELECTOR<br>my-<span class="hljs-keyword">session</span>   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">125</span>m   flink-main-container   apache/flink:<span class="hljs-number">1.14</span><span class="hljs-number">.5</span>-scala_2<span class="hljs-number">.12</span>   app=my-<span class="hljs-keyword">session</span>,component=jobmanager,<span class="hljs-keyword">type</span>=flink-native-kubernetes<br><br></code></pre></td></tr></table></figure><p>可以通过命令行提交，也可以通过dashboard提交任务</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">// run之后才会显示资源<br>$ ./bin/flink run \<br>    <span class="hljs-comment">--target kubernetes-session \</span><br>-Dkubernetes.namespace=flink-<span class="hljs-keyword">cluster</span> \<br>    -Dkubernetes.<span class="hljs-keyword">cluster</span>-id=my-<span class="hljs-keyword">session</span> \<br>    ./examples/streaming/TopSpeedWindowing.jar<br>$ ./bin/flink run     <span class="hljs-comment">--target kubernetes-session     -Dkubernetes.namespace=flink-cluster     -Dkubernetes.cluster-id=my-session   -Dparallelism.default=2  ./examples/streaming/TopSpeedWindowing.jar</span><br>//自动扩容功能测试<br>//一个taskmanager的任务槽使用完之前，<span class="hljs-keyword">cluster</span>只有一个task manager<br><span class="hljs-type">NAME</span>                          READY   STATUS    RESTARTS   AGE   IP          NODE           NOMINATED NODE   READINESS GATES<br>my-<span class="hljs-keyword">session</span><span class="hljs-number">-556</span>f44f44b-zdvrf   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">21</span>m   <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>   worker-node2   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>my-<span class="hljs-keyword">session</span>-taskmanager<span class="hljs-number">-1</span><span class="hljs-number">-1</span>    <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">20</span>m   <span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>   worker-node1   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>//继续提交作业，<span class="hljs-keyword">cluster</span>会自动扩容<br><span class="hljs-type">NAME</span>                          READY   STATUS    RESTARTS   AGE   IP          NODE           NOMINATED NODE   READINESS GATES<br>my-<span class="hljs-keyword">session</span><span class="hljs-number">-556</span>f44f44b-zdvrf   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">21</span>m   <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>   worker-node2   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>my-<span class="hljs-keyword">session</span>-taskmanager<span class="hljs-number">-1</span><span class="hljs-number">-1</span>    <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">20</span>m   <span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>   worker-node1   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>my-<span class="hljs-keyword">session</span>-taskmanager<span class="hljs-number">-1</span><span class="hljs-number">-2</span>    <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">34</span>s   <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>   worker-node2   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>//当两个taskmanager的资源都用完了<br>[root@master-node flink<span class="hljs-number">-1.14</span><span class="hljs-number">.5</span>]kubectl <span class="hljs-keyword">get</span> pods -n flink-<span class="hljs-keyword">cluster</span> -o wide<br><span class="hljs-type">NAME</span>                         READY   STATUS    RESTARTS   AGE     IP          NODE           NOMINATED NODE   READINESS GATES<br>my-<span class="hljs-keyword">session</span><span class="hljs-number">-58</span>bb97cdc<span class="hljs-number">-85</span>ssq   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">17</span>m     <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>   worker-node2   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>my-<span class="hljs-keyword">session</span>-taskmanager<span class="hljs-number">-1</span><span class="hljs-number">-1</span>   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">8</span>m26s   <span class="hljs-number">10.44</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span>   worker-node1   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>my-<span class="hljs-keyword">session</span>-taskmanager<span class="hljs-number">-1</span><span class="hljs-number">-2</span>   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">3</span>m11s   <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.3</span>   worker-node2   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>my-<span class="hljs-keyword">session</span>-taskmanager<span class="hljs-number">-1</span><span class="hljs-number">-3</span>   <span class="hljs-number">0</span>/<span class="hljs-number">1</span>     Pending   <span class="hljs-number">0</span>          <span class="hljs-number">33</span>s     &lt;<span class="hljs-keyword">none</span>&gt;      &lt;<span class="hljs-keyword">none</span>&gt;         &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br>//清理资源<br>$ kubectl <span class="hljs-keyword">delete</span> deployment/my-<span class="hljs-keyword">session</span> -n flink-<span class="hljs-keyword">cluster</span><br>$ kubectl <span class="hljs-keyword">delete</span> clusterrolebinding flink-<span class="hljs-keyword">role</span>-binding-flink<br>$ kubectl <span class="hljs-keyword">delete</span> serviceaccount flink -n flink-<span class="hljs-keyword">cluster</span><br>$ kubectl <span class="hljs-keyword">delete</span> namespace flink-<span class="hljs-keyword">cluster</span><br></code></pre></td></tr></table></figure><p>和独立部署相比，采用Native k8s部署有以下几个值得注意的点：</p><ol><li>JM 和TM 只能部署在K8s集群中的工作节点上，因此对于三个节点组成的k8s集群而言，Flink集群事实上只部署在其中两个节点上。因此对于小规模集群，我认为采用Native k8s部署有些浪费资源。</li><li>尽管机器为8核，但是如果直接将-Dtaskmanager.numberOfTaskSlots参数设为8，集群会启动失败，因为默认每个taskmanager会按照slots的数量来分配CPU。当前两个工作节点要部署一个JM，两个TM，导致JM必须和TM挤在同一个节点上，JM默认占1个CPU核，出了JM和TM外，还有一些系统进程也需要CPU，大概占0.1个CPU，因此我这里将-Dtaskmanager.numberOfTaskSlots设为6，经验证6.9也是ok的。 如果希望设置更大的slots数，可以修改kubernetes.taskmanager.cpu，让CPU数和slots数不再关联。</li><li>在独立部署中，不同的TM可以配置不同的内存，不同的slots数量。但在Native k8s部署中，这些参数是所有TM共享的，不可以分开配置。</li><li>从上面的操作过程可以看到，采用native k8s启动flink Session集群事实上仅仅启动了jobmanager。而taskmanager是在任务提交之后根据任务需要的资源数来启动的。在K8s集群资源的限制内，需要多少TM就启动多少TM对应的pod。任务结束对应的资源也会释放。资源的分配和调度都交给了k8s，相比手工设置，更加自动化。但是，如果我们不想要flink组件把k8s所有的节点都用完了，想要限定节点的范围改怎么办？下面是一个通过node-selector指定jobmanager的节点示例<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">//启动<span class="hljs-keyword">Session</span> cluster2, 修改配置<br>$ kubectl label nodes worker-node2 node=master<br>[root@master-node flink<span class="hljs-number">-1.14</span><span class="hljs-number">.5</span>]# kubectl <span class="hljs-keyword">get</span> nodes -l &quot;node=master&quot;<br><span class="hljs-type">NAME</span>           STATUS   ROLES    AGE   <span class="hljs-keyword">VERSION</span><br>worker-node2   Ready    worker   <span class="hljs-number">10</span>d   v1<span class="hljs-number">.24</span><span class="hljs-number">.2</span><br>$ ./bin/kubernetes-<span class="hljs-keyword">session</span>.sh -Dkubernetes.namespace=flink-<span class="hljs-keyword">cluster</span> -Dkubernetes.jobmanager.service-account=flink -Dkubernetes.<span class="hljs-keyword">cluster</span>-id=my-<span class="hljs-keyword">session</span> -Dtaskmanager.numberOfTaskSlots=<span class="hljs-number">8</span>  -D<br>kubernetes.rest-service.exposed.<span class="hljs-keyword">type</span>=NodePort -Dkubernetes.jobmanager.node-selector=node:master<br>[root@master-node flink<span class="hljs-number">-1.14</span><span class="hljs-number">.5</span>]# kubectl <span class="hljs-keyword">get</span> pods,svc,ep -n flink-<span class="hljs-keyword">cluster</span> -o wide<br><span class="hljs-type">NAME</span>                             READY   STATUS    RESTARTS   AGE   IP          NODE           NOMINATED NODE   READINESS GATES<br>pod/my-<span class="hljs-keyword">session</span><span class="hljs-number">-58</span>bb97cdc<span class="hljs-number">-85</span>ssq   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">57</span>s   <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>   worker-node2   &lt;<span class="hljs-keyword">none</span>&gt;           &lt;<span class="hljs-keyword">none</span>&gt;<br><br><span class="hljs-type">NAME</span>                      <span class="hljs-keyword">TYPE</span>        <span class="hljs-keyword">CLUSTER</span>-IP    <span class="hljs-keyword">EXTERNAL</span>-IP   PORT(S)             AGE   SELECTOR<br>service/my-<span class="hljs-keyword">session</span>        ClusterIP   <span class="hljs-keyword">None</span>          &lt;<span class="hljs-keyword">none</span>&gt;        <span class="hljs-number">6123</span>/TCP,<span class="hljs-number">6124</span>/TCP   <span class="hljs-number">57</span>s   app=my-<span class="hljs-keyword">session</span>,component=jobmanager,<span class="hljs-keyword">type</span>=flink-native-kubernetes<br>service/my-<span class="hljs-keyword">session</span>-rest   NodePort    <span class="hljs-number">10.108</span><span class="hljs-number">.58</span><span class="hljs-number">.5</span>   &lt;<span class="hljs-keyword">none</span>&gt;        <span class="hljs-number">8081</span>:<span class="hljs-number">31181</span>/TCP      <span class="hljs-number">57</span>s   app=my-<span class="hljs-keyword">session</span>,component=jobmanager,<span class="hljs-keyword">type</span>=flink-native-kubernetes<br><br><span class="hljs-type">NAME</span>                        ENDPOINTS                       AGE<br>endpoints/my-<span class="hljs-keyword">session</span>        <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6124</span>,<span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">6123</span>   <span class="hljs-number">57</span>s<br>endpoints/my-<span class="hljs-keyword">session</span>-rest   <span class="hljs-number">10.36</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>:<span class="hljs-number">8081</span>                  <span class="hljs-number">57</span>s<br></code></pre></td></tr></table></figure></li></ol><h2 id="启动集群（含高可用服务版本）"><a href="#启动集群（含高可用服务版本）" class="headerlink" title="启动集群（含高可用服务版本）"></a>启动集群（含高可用服务版本）</h2><p>高可用服务的部署需要一个可共享的持久化存储目录，因为部署在AWS上，这里我选择S3。<br>因此首先要解决的问题是如何让集群可以使用S3</p><h3 id="配置s3"><a href="#配置s3" class="headerlink" title="配置s3"></a>配置s3</h3><ol><li>首先要赋予EC2 访问S3 bucket的权限，这可以通过添加IAM实现。</li><li>Copy the respective JAR file（flink-s3-fs-hadoop-1.14.4.jar） from the opt directory to the plugins directory of your Flink distribution before starting Flink. 直接cp即可</li><li>启动集群的时候enable内置的插件就可以使用s3了<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">./bin/kubernetes-session<span class="hljs-selector-class">.sh</span><br>    -Dcontainerized<span class="hljs-selector-class">.master</span><span class="hljs-selector-class">.env</span>.ENABLE_BUILT_IN_PLUGINS=flink-s3-fs-hadoop-<span class="hljs-number">1.14</span>.<span class="hljs-number">4</span><span class="hljs-selector-class">.jar</span> \<br>    -Dcontainerized<span class="hljs-selector-class">.taskmanager</span><span class="hljs-selector-class">.env</span>.ENABLE_BUILT_IN_PLUGINS=flink-s3-fs-hadoop-<span class="hljs-number">1.14</span>.<span class="hljs-number">4</span>.jar<br></code></pre></td></tr></table></figure>Native k8s部署下使用s3的坑较多，各种报错。主要有两种：</li><li>没有s3访问的权限。检查IAM的配置，检查s3的访问控制。</li><li>找不到对应的类。这主要是插件没有使用对导致的。</li></ol><h3 id="启动高可用集群"><a href="#启动高可用集群" class="headerlink" title="启动高可用集群"></a>启动高可用集群</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">./bin/kubernetes-session.sh -Dkubernetes.<span class="hljs-attribute">namespace</span>=flink-cluster -Dkubernetes.jobmanager.<span class="hljs-attribute">service-account</span>=flink -Dkubernetes.<span class="hljs-attribute">cluster-id</span>=my-session -Dtaskmanager.<span class="hljs-attribute">numberOfTaskSlots</span>=6  -Dkubernetes.rest-service.exposed.<span class="hljs-attribute">type</span>=NodePort -Dcontainerized.master.env.<span class="hljs-attribute">ENABLE_BUILT_IN_PLUGINS</span>=flink-s3-fs-hadoop-1.14.5.jar -Dcontainerized.taskmanager.env.<span class="hljs-attribute">ENABLE_BUILT_IN_PLUGINS</span>=flink-s3-fs-hadoop-1.14.5.jar <span class="hljs-attribute">-Dhigh-availability</span>=org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory -Dhigh-availability.<span class="hljs-attribute">storageDir</span>=s3a://yunzpeng-bucket/flink-ha <br></code></pre></td></tr></table></figure><h2 id="总结：Native-k8s部署下session模式集群启动和作业提交过程"><a href="#总结：Native-k8s部署下session模式集群启动和作业提交过程" class="headerlink" title="总结：Native k8s部署下session模式集群启动和作业提交过程"></a>总结：Native k8s部署下session模式集群启动和作业提交过程</h2><p><img src="/2022/12/19/Flink%E9%83%A8%E7%BD%B2k8s%E7%AF%87/2022-12-22-00-00-17.png"></p><ul><li>第一个阶段：启动 Session Cluster。Flink Client 内置了 K8s Client，告诉 K8s Master 创建 Flink Master Deployment，ConfigMap，SVC。创建完成后，Master 就拉起来了。这时，Session 就部署完成了，并没有维护任何 TaskManager。</li><li>第二个阶段：当用户提交 Job 时，可以通过 Flink Client 或者 Dashboard 的方式，然后通过 Service 到 Dispatcher，Dispatcher 会产生一个 JobMaster。JobMaster 会向 K8sResourceManager 申请资源。ResourceManager 会发现现在没有任何可用的资源，它就会继续向 K8s 的 Master 去请求资源，请求资源之后将其发送回去，起新的 Taskmanager。Taskmanager 起来之后，再注册回来，此时的 ResourceManager 再向它去申请 slot 提供给 JobMaster，最后由 JobMaster 将相应的 Task 部署到 TaskManager 上。这样整个从 Session 的拉起到用户提交都完成了。</li></ul><h1 id="Applicatiob-Mode部署Flink-集群"><a href="#Applicatiob-Mode部署Flink-集群" class="headerlink" title="Applicatiob Mode部署Flink 集群"></a>Applicatiob Mode部署Flink 集群</h1><h2 id="无高可用"><a href="#无高可用" class="headerlink" title="无高可用"></a>无高可用</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 在root下操作<br><span class="hljs-regexp">//</span> <span class="hljs-number">1</span>. build a docker image with the flink job<br>FROM flink:<span class="hljs-number">1.14</span>.<span class="hljs-number">5</span><br>RUN mkdir -p <span class="hljs-variable">$FLINK_HOME</span>/usrlib<br>COPY .<span class="hljs-regexp">/examples/</span>streaming<span class="hljs-regexp">/TopSpeedWindowing.jar $FLINK_HOME/u</span>srlib/my-flink-job.jar<br>$ docker build -t pandafish1996/flink-demo .<br><span class="hljs-regexp">//</span> <span class="hljs-number">2</span>. Push image to image warehouse<br>$ docker login --username=pandafish1996<br><span class="hljs-regexp">//</span> 规范： docker push 注册用户名/镜像名<br><span class="hljs-regexp">//</span>$ docker tag yunzpeng<span class="hljs-regexp">/flink-word-count pandafish1996/</span>flink-word-count<br>$ docker push pandafish1996/flink-demo <br><br><span class="hljs-regexp">//</span><span class="hljs-number">3</span>. start a flink application cluster<br>$ kubectl create namespace flink-cluster<br>$ kubectl create serviceaccount flink -n flink-cluster<br>$ kubectl create clusterrolebinding flink-role-binding-flink \<br>  --clusterrole=edit \<br>  --serviceaccount=flink-cluster:flink<br><span class="hljs-regexp">//</span> without HA<br>$ .<span class="hljs-regexp">/bin/</span>flink run-application \<br>--target kubernetes-application \<br>-Dkubernetes.cluster-id=my-first-application-cluster \<br>-Dkubernetes.container.image=pandafish1996/flink-demo \<br>-Dkubernetes.namespace=flink-cluster \<br>-Dkubernetes.service-account=flink \<br>-Dparallelism.default=<span class="hljs-number">2</span> \<br>-Dtaskmanager.numberOfTaskSlots=<span class="hljs-number">6</span> \<br>-Dkubernetes.rest-service.exposed.type=NodePort  \<br>local:<span class="hljs-regexp">//</span><span class="hljs-regexp">/opt/</span>flink<span class="hljs-regexp">/usrlib/my</span>-flink-job.jar<br><br>$ kubectl <span class="hljs-keyword">delete</span> deployment/my-first-application-cluster -n flink-cluster<br></code></pre></td></tr></table></figure><h2 id="高可用版本"><a href="#高可用版本" class="headerlink" title="高可用版本"></a>高可用版本</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> <span class="hljs-number">1</span>. 构造image并上传到远程仓库<br>FROM flink:<span class="hljs-number">1.14</span>.<span class="hljs-number">5</span><br>RUN mkdir -p <span class="hljs-variable">$FLINK_HOME</span>/usrlib<br>COPY .<span class="hljs-regexp">/examples/</span>streaming<span class="hljs-regexp">/TopSpeedWindowing.jar $FLINK_HOME/u</span>srlib/my-flink-job.jar<br>RUN mkdir -p <span class="hljs-variable">$FLINK_HOME</span><span class="hljs-regexp">/plugins/</span>flink-s3-fs-hadoop<br>COPY .<span class="hljs-regexp">/opt/</span>flink-s3-fs-hadoop-<span class="hljs-number">1.14</span>.<span class="hljs-number">5</span>.jar <span class="hljs-variable">$FLINK_HOME</span><span class="hljs-regexp">/plugins/</span>flink-s3-fs-hadoop/<br>$ docker build -t pandafish1996/flink-hademo .<br>$ docker login --username=pandafish1996<br><span class="hljs-regexp">//</span> 规范： docker push 注册用户名/镜像名<br><span class="hljs-regexp">//</span>$ docker tag yunzpeng<span class="hljs-regexp">/flink-word-count pandafish1996/</span>flink-word-count<br>$ docker push pandafish1996/flink-hademo <br><span class="hljs-regexp">//</span> <span class="hljs-number">2</span>. 启动集群<br>.<span class="hljs-regexp">/bin/</span>flink run-application \<br>--target kubernetes-application \<br>-Dkubernetes.cluster-id=ha-cluster1 \<br>-Dkubernetes.container.image=pandafish1996/flink-hademo \<br>-Dkubernetes.namespace=flink-cluster \<br>-Dkubernetes.service-account=flink \<br>-Dparallelism.default=<span class="hljs-number">2</span> \<br>-Dtaskmanager.numberOfTaskSlots=<span class="hljs-number">6</span> \<br>-Dkubernetes.rest-service.exposed.type=NodePort  \<br>-Dhigh-availability=org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory \<br>-Dhigh-availability.storageDir=s3:<span class="hljs-regexp">//yu</span>nzpeng-bucket/flink-ha \<br>-Drestart-strategy=fixed-delay \<br>-Drestart-strategy.fixed-delay.attempts=<span class="hljs-number">10</span> \<br>-Dcontainerized.master.env.ENABLE_BUILT_IN_PLUGINS=flink-s3-fs-hadoop-<span class="hljs-number">1.14</span>.<span class="hljs-number">5</span>.jar \<br>-Dcontainerized.taskmanager.env.ENABLE_BUILT_IN_PLUGINS=flink-s3-fs-hadoop-<span class="hljs-number">1.14</span>.<span class="hljs-number">5</span>.jar \<br>local:<span class="hljs-regexp">//</span><span class="hljs-regexp">/opt/</span>flink<span class="hljs-regexp">/usrlib/my</span>-flink-job.jar<br></code></pre></td></tr></table></figure><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://www.infoq.cn/article/leekgketvkyte33rkjh0">Flink on K8s技术演进：如何原生地在Kubernetes上运行Flink？_大数据_王阳（亦祺）_InfoQ精选文章</a></li><li><a href="https://zhuanlan.zhihu.com/p/366485641">【Flink on k8s】Flink on Kubernetes 部署模式</a></li><li><a href="2%20Flink%E9%83%A8%E7%BD%B2%207665ee22770e4df2bde75507d05bfc91/Install_K8s_cluster_on_centos.docx">Install K8s cluster on centos.docx</a></li><li><a href="https://www.hostafrica.co.za/blog/new-technologies/install-kubernetes-delpoy-cluster-centos-7/">How to Install Kubernetes Cluster on CentOS 7 - HOSTAFRICA</a></li><li><a href="https://flink.apache.org/2021/02/10/native-k8s-with-ha.html">How to natively deploy Flink on Kubernetes with High-Availability (HA)</a></li><li><a href="https://cloud.tencent.com/developer/article/1839586">Flink 1.13 在Native k8s的部署实践</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
      <tag>Cluster Deployment</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ssh免密登录遇到过的坑</title>
    <link href="/2022/12/19/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E8%AF%A6%E8%A7%A3/"/>
    <url>/2022/12/19/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h1 id="ssh免密登录原理"><a href="#ssh免密登录原理" class="headerlink" title="ssh免密登录原理"></a>ssh免密登录原理</h1><p>通过非对称密钥实现认证登录，可参考<br><a href="https://cloud.tencent.com/developer/article/1484468">ssh免密登录原理与实现</a><br><a href="https://zhuanlan.zhihu.com/p/241341815">SSH 原理和基本应用</a></p><ol><li>客户端和服务器都生成自己的密钥对</li><li>客户端将公钥写入服务器的authorized_keys</li><li>ssh server远程访问服务器，发送连接请求，并发送id_rsa.pub公钥，服务器在本地的authorized_keys中查找是否存在该公钥，如果存在，用该公钥对任意字符串加密发送回客户端，客户端使用本地的id_rsa解密发送回服务器，服务器验证两个字符串是否相同。</li></ol><h1 id="ssh免密的登录设置方法"><a href="#ssh免密的登录设置方法" class="headerlink" title="ssh免密的登录设置方法"></a>ssh免密的登录设置方法</h1><ol><li>进入当前账号的home目录，进入.ssh文件夹</li><li>ssh-keygen 生成密钥对，输入命令后一直回车即可</li><li>复制公钥到远程服务器的.ssh目录下的authorized_keys文件中，有三种方法：<ol><li>ssh-copy-id命令</li><li>scp命令</li><li>手工复制粘贴</li></ol></li></ol><h1 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h1><h2 id="非root账号"><a href="#非root账号" class="headerlink" title="非root账号"></a>非root账号</h2><ol><li>非root账号下设置ssh免密登录，使用ssh-copy-id命令会要求输入远程服务器的root密码，可通过手工复制粘贴解决。</li></ol><h2 id="root账号"><a href="#root账号" class="headerlink" title="root账号"></a>root账号</h2><p>root账号下设置ssh免密登录后，始终要求输入root密码。<br>解决思路：</p><ol><li>检查本地生成密钥的.ssh文件夹和远程服务器上公钥复制粘贴操作的.ssh文件夹是否都是&#x2F;root目录下的。我刚开始是把登录账号的.ssh目录和root账号的.ssh目录混在了一起。注意，在某账号下ssh server1相当于ssh 账号名@server1，不同账号的远程登录目录不一样，检索的位置就不一样。</li><li>检查etc&#x2F;ssh&#x2F;sshd_config配置，DenyUsers root, DenyGroups root这两行代表禁止通过远程访问根用户，需要注释掉。其它的配置也需要检查。这里我粘贴一下我最终的配置。<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">#$OpenBSD: sshd_config,v 1.100 2016/08/15 12:32:04 naddy Exp $</span><br><br><span class="hljs-comment"># This is the sshd server system-wide configuration file.  See</span><br><span class="hljs-comment"># sshd_config(5) for more information.</span><br><br><span class="hljs-comment"># This sshd was compiled with PATH=/usr/local/bin:/usr/bin</span><br><br><span class="hljs-comment"># The strategy used for options in the default sshd_config shipped with</span><br><span class="hljs-comment"># OpenSSH is to specify options with their default value where</span><br><span class="hljs-comment"># possible, but leave them commented.  Uncommented options override the</span><br><span class="hljs-comment"># default value.</span><br><br><span class="hljs-comment"># If you want to change the port on a SELinux system, you have to tell</span><br><span class="hljs-comment"># SELinux about this change.</span><br><span class="hljs-comment"># semanage port -a -t ssh_port_t -p tcp #PORTNUMBER</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#Port 22</span><br><span class="hljs-comment">#AddressFamily any</span><br><span class="hljs-comment">#ListenAddress 0.0.0.0</span><br><span class="hljs-comment">#ListenAddress ::</span><br><br>HostKey /etc/ssh/ssh_host_rsa_key<br><span class="hljs-comment">#HostKey /etc/ssh/ssh_host_dsa_key</span><br>HostKey /etc/ssh/ssh_host_ecdsa_key<br>HostKey /etc/ssh/ssh_host_ed25519_key<br><br><span class="hljs-comment"># Ciphers and keying</span><br><span class="hljs-comment">#RekeyLimit default none</span><br><br><span class="hljs-comment"># Logging</span><br><span class="hljs-comment">#SyslogFacility AUTH</span><br>SyslogFacility AUTHPRIV<br>LogLevel <span class="hljs-built_in">INFO</span><br><br><span class="hljs-comment"># Authentication:</span><br><br>LoginGraceTime 60<br>PermitRootLogin <span class="hljs-literal">yes</span><br><span class="hljs-comment">#StrictModes yes</span><br>MaxAuthTries 4<br><span class="hljs-comment">#MaxSessions 10</span><br><br>PubkeyAuthentication <span class="hljs-literal">yes</span><br><br><span class="hljs-comment"># The default is to check both .ssh/authorized_keys and .ssh/authorized_keys2</span><br><span class="hljs-comment"># but this is overridden so installations will only check .ssh/authorized_keys</span><br>AuthorizedKeysFile.ssh/authorized_keys<br><br><span class="hljs-comment">#AuthorizedPrincipalsFile none</span><br><br><span class="hljs-comment">#AuthorizedKeysCommand none</span><br><span class="hljs-comment">#AuthorizedKeysCommandUser nobody</span><br><br><span class="hljs-comment"># For this to work you will also need host keys in /etc/ssh/ssh_known_hosts</span><br>HostbasedAuthentication <span class="hljs-literal">no</span><br><span class="hljs-comment"># Change to yes if you don&#x27;t trust ~/.ssh/known_hosts for</span><br><span class="hljs-comment"># HostbasedAuthentication</span><br><span class="hljs-comment">#IgnoreUserKnownHosts no</span><br><span class="hljs-comment"># Don&#x27;t read the user&#x27;s ~/.rhosts and ~/.shosts files</span><br>IgnoreRhosts <span class="hljs-literal">yes</span><br><br><span class="hljs-comment"># To disable tunneled clear text passwords, change to no here!</span><br><span class="hljs-comment">#PasswordAuthentication yes</span><br>PermitEmptyPasswords <span class="hljs-literal">no</span><br>PasswordAuthentication <span class="hljs-literal">yes</span><br><br><span class="hljs-comment"># Change to no to disable s/key passwords</span><br><span class="hljs-comment">#ChallengeResponseAuthentication yes</span><br>ChallengeResponseAuthentication <span class="hljs-literal">yes</span><br><br><span class="hljs-comment"># Kerberos options</span><br><span class="hljs-comment">#KerberosAuthentication no</span><br><span class="hljs-comment">#KerberosOrLocalPasswd yes</span><br><span class="hljs-comment">#KerberosTicketCleanup yes</span><br><span class="hljs-comment">#KerberosGetAFSToken no</span><br><span class="hljs-comment">#KerberosUseKuserok yes</span><br><br><span class="hljs-comment"># GSSAPI options</span><br>GSSAPIAuthentication <span class="hljs-literal">yes</span><br>GSSAPICleanupCredentials <span class="hljs-literal">no</span><br><span class="hljs-comment">#GSSAPIStrictAcceptorCheck yes</span><br><span class="hljs-comment">#GSSAPIKeyExchange no</span><br><span class="hljs-comment">#GSSAPIEnablek5users no</span><br><br><span class="hljs-comment"># Set this to &#x27;yes&#x27; to enable PAM authentication, account processing,</span><br><span class="hljs-comment"># and session processing. If this is enabled, PAM authentication will</span><br><span class="hljs-comment"># be allowed through the ChallengeResponseAuthentication and</span><br><span class="hljs-comment"># PasswordAuthentication.  Depending on your PAM configuration,</span><br><span class="hljs-comment"># PAM authentication via ChallengeResponseAuthentication may bypass</span><br><span class="hljs-comment"># the setting of &quot;PermitRootLogin without-password&quot;.</span><br><span class="hljs-comment"># If you just want the PAM account and session checks to run without</span><br><span class="hljs-comment"># PAM authentication, then enable this but set PasswordAuthentication</span><br><span class="hljs-comment"># and ChallengeResponseAuthentication to &#x27;no&#x27;.</span><br><span class="hljs-comment"># WARNING: &#x27;UsePAM no&#x27; is not supported in Red Hat Enterprise Linux and may cause several</span><br><span class="hljs-comment"># problems.</span><br>UsePAM <span class="hljs-literal">yes</span><br><br><span class="hljs-comment">#AllowAgentForwarding yes</span><br><span class="hljs-comment">#AllowTcpForwarding yes</span><br><span class="hljs-comment">#GatewayPorts no</span><br>X11Forwarding <span class="hljs-literal">no</span><br><span class="hljs-comment">#X11DisplayOffset 10</span><br><span class="hljs-comment">#X11UseLocalhost yes</span><br><span class="hljs-comment">#PermitTTY yes</span><br><span class="hljs-comment">#PrintMotd yes</span><br><span class="hljs-comment">#PrintLastLog yes</span><br><span class="hljs-comment">#TCPKeepAlive yes</span><br><span class="hljs-comment">#UseLogin no</span><br><span class="hljs-comment">#UsePrivilegeSeparation sandbox</span><br>PermitUserEnvironment <span class="hljs-literal">no</span><br><span class="hljs-comment">#Compression delayed</span><br>ClientAliveInterval 600<br>ClientAliveCountMax 0<br><span class="hljs-comment">#ShowPatchLevel no</span><br><span class="hljs-comment">#UseDNS yes</span><br><span class="hljs-comment">#PidFile /var/run/sshd.pid</span><br><span class="hljs-comment">#MaxStartups 10:30:100</span><br><span class="hljs-comment">#PermitTunnel no</span><br><span class="hljs-comment">#ChrootDirectory none</span><br><span class="hljs-comment">#VersionAddendum none</span><br><br><span class="hljs-comment"># no default banner path</span><br>Banner /etc/issue.net<br><br><span class="hljs-comment"># Accept locale-related environment variables</span><br>AcceptEnv LANG LC_CTYPE LC_NUMERIC LC_TIME LC_COLLATE LC_MONETARY LC_MESSAGES<br>AcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENT<br>AcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGE<br>AcceptEnv XMODIFIERS<br><br><span class="hljs-comment"># override default of no subsystems</span><br>Subsystemsftp/usr/libexec/openssh/sftp-server<br><br><span class="hljs-comment"># Example of overriding settings on a per-user basis</span><br><span class="hljs-comment">#Match User anoncvs</span><br><span class="hljs-comment">#X11Forwarding no</span><br><span class="hljs-comment">#AllowTcpForwarding no</span><br><span class="hljs-comment">#PermitTTY no</span><br><span class="hljs-comment">#ForceCommand cvs server</span><br>Ciphers 隐藏<br><span class="hljs-comment"># DenyUsers root</span><br><span class="hljs-comment"># DenyGroups root</span><br>AllowTcpForwarding <span class="hljs-literal">no</span><br>MaxStartups 10:30:60<br>MaxSessions 4<br></code></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Cluster Deployment</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从0开始部署一个Flink集群：实践篇（独立部署）</title>
    <link href="/2022/12/18/Flink%E9%83%A8%E7%BD%B2%E7%8B%AC%E7%AB%8B%E9%83%A8%E7%BD%B2%E7%AF%87/"/>
    <url>/2022/12/18/Flink%E9%83%A8%E7%BD%B2%E7%8B%AC%E7%AB%8B%E9%83%A8%E7%BD%B2%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<ul><li>服务器操作系统：centos7</li><li>本机操作系统：Mac</li><li>Flink version: 1.15</li><li>JDK version: java11</li><li>HA service: Zookeeper</li><li>File System: NFS</li></ul><p>资源分配：</p><table><thead><tr><th>ip</th><th>hostname</th><th>role</th></tr></thead><tbody><tr><td>10.250.0.1</td><td>main0</td><td>JM</td></tr><tr><td>10.250.0.2</td><td>main1</td><td>JM</td></tr><tr><td>10.250.0.3</td><td>main2</td><td>JM</td></tr><tr><td>10.250.0.4</td><td>worker1</td><td>TM</td></tr><tr><td>10.250.0.5</td><td>worker2</td><td>TM</td></tr></tbody></table><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><p>远程登录工具：iTerm</p><p>远程登录5台服务器，⌘(command) + ⇧(shift) + i快捷键同时操作它们。若登录账号非root账号，建议切换为root账号</p><h2 id="关闭SeLinux"><a href="#关闭SeLinux" class="headerlink" title="关闭SeLinux"></a>关闭SeLinux</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">setenforce 0</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sed -i --follow-symlinks <span class="hljs-string">&#x27;s/SELINUX=enforcing/SELINUX=disabled/g&#x27;</span> /etc/sysconfig/selinux</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">reboot</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sestatus</span><br></code></pre></td></tr></table></figure><h2 id="配置hostname"><a href="#配置hostname" class="headerlink" title="配置hostname"></a>配置hostname</h2><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">$ hostnamectl set-hostname main0 #main1,main2,worker1~<span class="hljs-number">2</span><br>$ hostnamectl status<br>$ vi /etc/hosts <br>$ cat /etc/hosts<br><span class="hljs-number">127.0.0.1</span> localhost localhost.localdomain localhost4 localhost4.localdomain4<br>::<span class="hljs-number">1</span> localhost localhost.localdomain localhost6 localhost6.localdomain6<br><span class="hljs-number">10.250.0.1</span>: main0<br><span class="hljs-number">10.250.0.2</span>: main1<br><span class="hljs-number">10.250.0.3</span>: main2<br><span class="hljs-number">10.250.0.4</span>: worker1<br><span class="hljs-number">10.250.0.5</span>: worker2<br></code></pre></td></tr></table></figure><h2 id="同步时间"><a href="#同步时间" class="headerlink" title="同步时间"></a>同步时间</h2><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>yum install ntp -y<br><span class="hljs-variable">$ </span>crontab -e<br><span class="hljs-variable">$ </span>crontab -l<br><span class="hljs-number">0</span> * * * * <span class="hljs-regexp">/usr/sbin</span><span class="hljs-regexp">/ntpdate cn.pool.ntp.org</span><br></code></pre></td></tr></table></figure><h2 id="配置ssh免密登录"><a href="#配置ssh免密登录" class="headerlink" title="配置ssh免密登录"></a>配置ssh免密登录</h2><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment"># 1. 生成密钥</span><br><span class="hljs-variable">$ </span>ssh-keygen<br><span class="hljs-comment"># 2. 复制各自的公钥到其它服务器的authorized_key</span><br><span class="hljs-variable">$ </span>ssh-copy-id -i ~<span class="hljs-regexp">/.ssh/id</span>_rsa.pub main0 <span class="hljs-comment">#main1,main2,worker1~2</span><br></code></pre></td></tr></table></figure><p>关于复制公钥涉及到服务器之间的相互访问，可能会要求你输入root账号的密码，如果不知道可以通过手工复制粘贴代替ssh-copy-id命令。</p><p>详情可参考：<br><a href="https://yunzhen.github.io/2022/12/19/ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95%E8%AF%A6%E8%A7%A3/">ssh免密登录遇到过的坑</a></p><h2 id="安装Java11"><a href="#安装Java11" class="headerlink" title="安装Java11"></a>安装Java11</h2><p>安装flink之前需要装好java，1.15之后的版本只支持java11，不再支持java8.</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">$ yum search <span class="hljs-keyword">java|grep </span><span class="hljs-keyword">jdk</span><br><span class="hljs-keyword"></span>$ yum <span class="hljs-keyword">install </span>-y <span class="hljs-keyword">java-11-openjdk</span><br><span class="hljs-keyword"></span>$ yum <span class="hljs-keyword">install </span><span class="hljs-keyword">java-11-openjdk-devel </span>-y<br>$ <span class="hljs-keyword">java </span>-version<br></code></pre></td></tr></table></figure><h1 id="Zookeeper-HA-服务环境准备"><a href="#Zookeeper-HA-服务环境准备" class="headerlink" title="Zookeeper HA 服务环境准备"></a>Zookeeper HA 服务环境准备</h1><h2 id="Zookeeper集群搭建"><a href="#Zookeeper集群搭建" class="headerlink" title="Zookeeper集群搭建"></a>Zookeeper集群搭建</h2><p>Standalone部署模式下的flink集群只支持zookeeper高可用服务，所以若要部署Jobmanager高可用，必须部署zookeeper。</p><p>我选择将所有安装包都安装在&#x2F;opt目录下。zookeeper只涉及到前三台服务器，因此以下操作仅用于前三台服务器（main0,main1,main2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cd</span> /opt</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">wget https://dlcdn.apache.org/zookeeper/zookeeper-3.7.1/apache-zookeeper-3.7.1-bin.tar.gz --no-check-certificate</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">tar -xzf apache-zookeeper-3.7.1-bin.tar.gz<span class="hljs-string">&#x27;</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-string">重命名</span></span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-string">mv apache-zookeeper-3.7.1 zookeeper</span></span><br></code></pre></td></tr></table></figure><p>进入解压后的目录，修改配置文件zoo.cfg（默认只有zoo_sample.cfg，zoo.cfg需要自建）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># The number of milliseconds of each tick</span><br><span class="hljs-string">tickTime=2000</span><br><span class="hljs-comment"># The number of ticks that the initial</span><br><span class="hljs-comment"># synchronization phase can take</span><br><span class="hljs-string">initLimit=10</span><br><span class="hljs-comment"># The number of ticks that can pass between</span><br><span class="hljs-comment"># sending a request and getting an acknowledgement</span><br><span class="hljs-string">syncLimit=5</span><br><span class="hljs-comment"># the directory where the snapshot is stored.</span><br><span class="hljs-comment"># do not use /tmp for storage, /tmp here is just</span><br><span class="hljs-comment"># example sakes.</span><br><span class="hljs-string">dataDir=/opt/zookeeper/data</span><br><span class="hljs-string">dataLogDir=/opt/zookeeper/logs</span><br><span class="hljs-comment"># the port at which the clients will connect</span><br><span class="hljs-string">clientPort=2181</span><br><span class="hljs-comment"># the maximum number of client connections.</span><br><span class="hljs-comment"># increase this if you need to handle more clients</span><br><span class="hljs-comment">#maxClientCnxns=60</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># Be sure to read the maintenance section of the</span><br><span class="hljs-comment"># administrator guide before turning on autopurge.</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># The number of snapshots to retain in dataDir</span><br><span class="hljs-comment">#autopurge.snapRetainCount=3</span><br><span class="hljs-comment"># Purge task interval in hours</span><br><span class="hljs-comment"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="hljs-comment">#autopurge.purgeInterval=1</span><br><br><span class="hljs-comment">## Metrics Providers</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># https://prometheus.io Metrics Exporter</span><br><span class="hljs-comment">#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider</span><br><span class="hljs-comment">#metricsProvider.httpPort=7000</span><br><span class="hljs-comment">#metricsProvider.exportJvmInfo=true</span><br><span class="hljs-string">server.1=10.250.0.1:2888:3888</span><br><span class="hljs-string">server.2=10.250.0.2:2888:3888</span><br><span class="hljs-string">server.3=10.250.0.3:2888:3888</span><br></code></pre></td></tr></table></figure><p>进入配置文件中定义的dataDir目录，创建myid文件，在myid文件中写入各自的id。配置文件中server.1&#x3D;10.250.0.1:2888:3888里面的server.1 1就是id号。因此myid文件分别写入1，2，3即可。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cd</span> /opt/zookeeper/data</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">vi myid</span><br>  1  # 三台机器不一样，其它为2，3<br><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">nohup</span> bin/zkServer.sh start &gt;&gt; /dev/null 2&gt;&amp;1 &amp;</span><br></code></pre></td></tr></table></figure><p>启动后可通过 ps -aux|grep zkServer 命令查看进程是否启动成功。也可以通过jps命令查看是否有QuorumPeerMain进程</p><p>启动失败可以进入&#x2F;opt&#x2F;zookeeper&#x2F;logs查看对应的log。我这边的失败原因有：myid配置目录和zoo.cfg文件中的dataDir不一致；端口被占用。</p><h2 id="NFS-配置"><a href="#NFS-配置" class="headerlink" title="NFS 配置"></a>NFS 配置</h2><p>之所以配置NFS是因为配置Flink的zookeeper HA 服务需要配置可共享的文件存储（High-availability.storageDir must be a durable file system that is accessible from all nodes）官方示例给的hdfs，但是考虑到hdfs太笨重，我们的任务量也不大，我选择了更轻量的NFS。我的NFS服务是直接向同事申请的，同事提供了远程目录，我直接挂载到我的三台jobmanager服务器的&#x2F;mnt&#x2F;flink&#x2F;ha&#x2F;位置，之后这个目录就将配置为flink中的High-availability.storageDir</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">rpm -qa|grep nfs</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">rpm -qa|grep rpc</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-keyword">if</span> not installed, install nfs</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">yum -y install nfs-utils rpcbind</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">verify</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">rpm -qa nfs-utils rpcbind</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">moutn <span class="hljs-built_in">local</span> <span class="hljs-built_in">dir</span> to remote <span class="hljs-built_in">dir</span></span><br>mount -t nfs -o nolock 远程目录 /mnt/flink/ha/<br></code></pre></td></tr></table></figure><h1 id="Flink集群部署与配置"><a href="#Flink集群部署与配置" class="headerlink" title="Flink集群部署与配置"></a>Flink集群部署与配置</h1><p>下面操作对象为所有服务器</p><h2 id="下载并解压"><a href="#下载并解压" class="headerlink" title="下载并解压"></a>下载并解压</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cd</span> /opt</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">wget https://dlcdn.apache.org/flink/flink-1.15.2/flink-1.15.2-bin-scala_2.12.tgz --no-check-certificate</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">tar -xzf flink-*.tgz</span><br></code></pre></td></tr></table></figure><h2 id="Configure-masters-in-conf-x2F-masters"><a href="#Configure-masters-in-conf-x2F-masters" class="headerlink" title="Configure masters in conf&#x2F;masters:"></a>Configure masters in conf&#x2F;masters:</h2><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">main0</span>:<span class="hljs-number">8081</span><br><span class="hljs-attribute">main1</span>:<span class="hljs-number">8081</span><br><span class="hljs-attribute">main2</span>:<span class="hljs-number">8081</span><br></code></pre></td></tr></table></figure><h2 id="Configure-workers-in-conf-x2F-workers"><a href="#Configure-workers-in-conf-x2F-workers" class="headerlink" title="Configure workers in conf&#x2F;workers:"></a>Configure workers in conf&#x2F;workers:</h2><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">worker1</span><br>worker2<br></code></pre></td></tr></table></figure><h2 id="配置-conf-x2F-flink-conf-yaml"><a href="#配置-conf-x2F-flink-conf-yaml" class="headerlink" title="配置 conf&#x2F;flink-conf.yaml"></a>配置 conf&#x2F;flink-conf.yaml</h2><p>完整文件太长，不同机器不完全一样，下面仅列出worker1的配置项（去除了注释）</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">jobmanager.rpc.address:</span> <span class="hljs-string">localhost</span><br><span class="hljs-attr">jobmanager.rpc.port:</span> <span class="hljs-number">6123</span><br><span class="hljs-attr">jobmanager.bind-host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">jobmanager.memory.process.size:</span> <span class="hljs-string">1600m</span><br><span class="hljs-attr">taskmanager.bind-host:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">taskmanager.host:</span> <span class="hljs-string">worker1(服务器worker2上写worker2)</span><br><span class="hljs-attr">taskmanager.memory.process.size:</span> <span class="hljs-string">8192m</span><br><span class="hljs-attr">taskmanager.memory.managed.size:</span> <span class="hljs-string">0m</span><br><span class="hljs-attr">taskmanager.numberOfTaskSlots:</span> <span class="hljs-number">8</span><br><span class="hljs-attr">parallelism.default:</span> <span class="hljs-number">1</span><br><span class="hljs-attr">high-availability:</span> <span class="hljs-string">zookeeper</span><br><span class="hljs-attr">high-availability.storageDir:</span> <span class="hljs-string">file:///mnt/flink/ha/</span><br><span class="hljs-attr">high-availability.zookeeper.quorum:</span> <span class="hljs-string">main0:2181,main1:2181,main2:2181</span><br><span class="hljs-attr">high-availability.zookeeper.path.root:</span> <span class="hljs-string">/opt/flink-1.15.2/cluster_nodes</span><br><span class="hljs-attr">high-availability.cluster-id:</span> <span class="hljs-string">/cluster_one</span><br><span class="hljs-attr">jobmanager.execution.failover-strategy:</span> <span class="hljs-string">region</span><br><span class="hljs-attr">rest.address:</span> <span class="hljs-string">localhost</span><br><span class="hljs-attr">rest.bind-address:</span> <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span><br></code></pre></td></tr></table></figure><h2 id="启动和关闭集群"><a href="#启动和关闭集群" class="headerlink" title="启动和关闭集群"></a>启动和关闭集群</h2><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"># <span class="hljs-keyword">start</span> <span class="hljs-keyword">cluster</span><br>$ bin/<span class="hljs-keyword">start</span>-<span class="hljs-keyword">cluster</span>.sh<br># <span class="hljs-keyword">close</span> <span class="hljs-keyword">cluster</span><br>$ bin/stop-<span class="hljs-keyword">cluster</span>.sh<br></code></pre></td></tr></table></figure><p>开启集群后可以在10.250.0.1：8081上看到UI界面<br><img src="/2022/12/18/Flink%E9%83%A8%E7%BD%B2%E7%8B%AC%E7%AB%8B%E9%83%A8%E7%BD%B2%E7%AF%87/2022-12-19-17-48-28.png"></p><p>启动集群后也可以关闭具体的某个taskmanager</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">bin/taskmanager.sh stop</span><br></code></pre></td></tr></table></figure><p>同一台机器可以启动多个taskmanager（前提是资源够）</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> bin/taskmanager.sh <span class="hljs-built_in">start</span><br></code></pre></td></tr></table></figure><h1 id="Flink集群功能测试"><a href="#Flink集群功能测试" class="headerlink" title="Flink集群功能测试"></a>Flink集群功能测试</h1><p>关掉或kill掉一个taskmanager，可以看到运行的任务重启在另一个taskmanager上。</p><p>关掉或kill掉当前的jobmanager leader，可以在另一个jobmanager的 UI界面上监测到任务从恢复点恢复。</p>]]></content>
    
    
    <categories>
      
      <category>Flink</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flink</tag>
      
      <tag>Cluster Deployment</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
